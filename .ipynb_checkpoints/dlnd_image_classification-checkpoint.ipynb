{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:24, 6.95MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febff796898>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    ##return a normalized array with the same shape as x\n",
    "    \n",
    "   \n",
    "    return x/255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "f = pd.get_dummies([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    o = np.zeros((len(x),10))\n",
    "    for i in range(len(x)):\n",
    "        o[i] = f[x[i]] \n",
    "    \n",
    "    return o\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    height = image_shape[0]\n",
    "    width  = image_shape[1]\n",
    "    chan   = image_shape[2]\n",
    "    image_input = tf.placeholder(tf.float32, shape=(None,height, width, chan), name='x')\n",
    "    \n",
    "    return image_input\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    \n",
    "    label_input = tf.placeholder(tf.float32, shape=(None, n_classes), name='y')\n",
    "    \n",
    "    return label_input\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    Implement neural_net_keep_prob_input\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return keep_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    # x_tensor = tensor(None,32,32,5)\n",
    "    # conv_num_outputs = 10\n",
    "    # conv_ksize = (2,2)\n",
    "    # conv_strides = (4,4)\n",
    "    # pool_ksize = (2,2)\n",
    "    # pool_strides = (2,2)\n",
    "    \n",
    "    #---------------------\n",
    "    # without .as_list() we get the following error:\n",
    "    # Expected binary or unicode string, got 2\n",
    "    #---------------------\n",
    "    tensor_shape = x_tensor.get_shape().as_list()\n",
    "    tshape_d = tensor_shape[3]\n",
    "    \n",
    "    #filter\n",
    "    f_size_height = conv_ksize[0]\n",
    "    f_size_width  = conv_ksize[1]\n",
    "    \n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal([f_size_height,f_size_width, tshape_d, conv_num_outputs], \\\n",
    "                                             mean=0.0, stddev=0.05, dtype=tf.float32), name='weight')\n",
    "    \n",
    "    bias   = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #convolution layer\n",
    "    conv_layer = tf.nn.conv2d(x_tensor,\\\n",
    "                              weight,\\\n",
    "                              strides=[1,conv_strides[0],conv_strides[1],1],\\\n",
    "                              padding = 'SAME')\n",
    "    #bias\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    #activation\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    #max pooling\n",
    "    \n",
    "    conv_layer = tf.nn.max_pool(conv_layer,\\\n",
    "                                ksize=[1, pool_ksize[0], pool_ksize[1],1],\\\n",
    "                                strides=[1, pool_strides[0], pool_strides[1], 1],\\\n",
    "                                padding='SAME')\n",
    "    \n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #using layers contrib\n",
    "    flt = tf.contrib.layers.flatten(x_tensor,[-1,2])\n",
    "    \n",
    "    \n",
    "    return flt \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape  = x_tensor.get_shape().as_list()\n",
    "    weight = tf.Variable(tf.truncated_normal([shape[1], num_outputs],mean=0.0, stddev=0.05, dtype=tf.float32))\n",
    "    bias   = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    fc   =   tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    return tf.nn.relu(fc)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape  = x_tensor.get_shape().as_list()\n",
    "    weight = tf.Variable(tf.truncated_normal([shape[1], num_outputs], mean=0.0, stddev=0.05, dtype=tf.float32))\n",
    "    bias   = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    \n",
    "    conv1 = conv2d_maxpool(x, 64, [3,3],[2,2],[2,2],[2,2])\n",
    "    conv2 = conv2d_maxpool(conv1, 128, [3,3],[2,2],[2,2],[2,2])\n",
    "    \n",
    "    fl = flatten(conv2)\n",
    "    fl = tf.nn.dropout(fl, keep_prob)\n",
    "    \n",
    "    fc1   = fully_conn(fl, 256)\n",
    "    fc1   = tf.nn.dropout(fc1, keep_prob)\n",
    "    fc1   = tf.nn.relu(fc1)\n",
    "    \n",
    "    out = output(fc1, 10)\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer,\n",
    "               feed_dict={\n",
    "                   x: feature_batch,\n",
    "                   y: label_batch,\n",
    "                   keep_prob: keep_probability\n",
    "               })\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost,\n",
    "                      feed_dict={\n",
    "                          x: feature_batch,\n",
    "                          y: label_batch,\n",
    "                          keep_prob: 1.0\n",
    "                      })\n",
    "    valid_acc = session.run(accuracy,\n",
    "                           feed_dict={\n",
    "                               x: valid_features,\n",
    "                               y: valid_labels,\n",
    "                               keep_prob:1.0\n",
    "                           })\n",
    "    \n",
    "    print('Loss: {:.4f}  Validation Accuracy: {:.2f}%'.format(loss, valid_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 1024\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2402  Validation Accuracy: 23.76%\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.0762  Validation Accuracy: 27.04%\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.0113  Validation Accuracy: 28.72%\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.9599  Validation Accuracy: 31.96%\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.8639  Validation Accuracy: 34.74%\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.8043  Validation Accuracy: 36.78%\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.7607  Validation Accuracy: 38.60%\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.7264  Validation Accuracy: 38.24%\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.6780  Validation Accuracy: 39.82%\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.6444  Validation Accuracy: 40.56%\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.6160  Validation Accuracy: 41.60%\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.5828  Validation Accuracy: 42.06%\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.5671  Validation Accuracy: 42.66%\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.5416  Validation Accuracy: 42.90%\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.4997  Validation Accuracy: 44.30%\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.4785  Validation Accuracy: 44.70%\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.4556  Validation Accuracy: 44.84%\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.4409  Validation Accuracy: 45.40%\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.4256  Validation Accuracy: 45.72%\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.3965  Validation Accuracy: 46.48%\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.3752  Validation Accuracy: 47.24%\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.3620  Validation Accuracy: 47.46%\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.3373  Validation Accuracy: 47.98%\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.3192  Validation Accuracy: 48.54%\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.3015  Validation Accuracy: 49.08%\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.2867  Validation Accuracy: 49.74%\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.2716  Validation Accuracy: 50.06%\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.2578  Validation Accuracy: 50.24%\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.2488  Validation Accuracy: 50.44%\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.2292  Validation Accuracy: 51.08%\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.2121  Validation Accuracy: 51.40%\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.2000  Validation Accuracy: 51.58%\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.1934  Validation Accuracy: 51.26%\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.1832  Validation Accuracy: 51.86%\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.1637  Validation Accuracy: 52.26%\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.1490  Validation Accuracy: 52.68%\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.1339  Validation Accuracy: 52.98%\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.1443  Validation Accuracy: 52.26%\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.1164  Validation Accuracy: 53.22%\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.0926  Validation Accuracy: 53.66%\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.0866  Validation Accuracy: 53.58%\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.0736  Validation Accuracy: 53.30%\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.0719  Validation Accuracy: 54.16%\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.0528  Validation Accuracy: 53.74%\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.0493  Validation Accuracy: 54.18%\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.0273  Validation Accuracy: 54.76%\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.0201  Validation Accuracy: 54.72%\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.0051  Validation Accuracy: 55.28%\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.9996  Validation Accuracy: 55.30%\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.9871  Validation Accuracy: 55.08%\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.9834  Validation Accuracy: 55.60%\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.9588  Validation Accuracy: 55.60%\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.9516  Validation Accuracy: 56.00%\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.9407  Validation Accuracy: 55.94%\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.9482  Validation Accuracy: 55.24%\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.9145  Validation Accuracy: 56.52%\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.9129  Validation Accuracy: 56.64%\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.9235  Validation Accuracy: 55.64%\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.8917  Validation Accuracy: 56.94%\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.8909  Validation Accuracy: 56.58%\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.8841  Validation Accuracy: 56.98%\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.8607  Validation Accuracy: 57.34%\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.8686  Validation Accuracy: 56.50%\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.8745  Validation Accuracy: 55.90%\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.8570  Validation Accuracy: 56.76%\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.8706  Validation Accuracy: 56.04%\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.8403  Validation Accuracy: 56.56%\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.8205  Validation Accuracy: 57.38%\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.8196  Validation Accuracy: 56.74%\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.7975  Validation Accuracy: 57.60%\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.7769  Validation Accuracy: 57.56%\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.7806  Validation Accuracy: 57.88%\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.7689  Validation Accuracy: 57.82%\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.7456  Validation Accuracy: 57.96%\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.7309  Validation Accuracy: 58.24%\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.7260  Validation Accuracy: 57.90%\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.7119  Validation Accuracy: 58.54%\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.7069  Validation Accuracy: 58.42%\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.7011  Validation Accuracy: 58.26%\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.6875  Validation Accuracy: 58.90%\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.6754  Validation Accuracy: 59.08%\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.6742  Validation Accuracy: 58.72%\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.6569  Validation Accuracy: 58.74%\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.6531  Validation Accuracy: 59.24%\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.6572  Validation Accuracy: 58.36%\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.6353  Validation Accuracy: 59.18%\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.6373  Validation Accuracy: 59.00%\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.6202  Validation Accuracy: 59.26%\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.6153  Validation Accuracy: 58.94%\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.6100  Validation Accuracy: 59.06%\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.6006  Validation Accuracy: 59.14%\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.5897  Validation Accuracy: 59.78%\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.5780  Validation Accuracy: 59.58%\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.5749  Validation Accuracy: 59.78%\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.5659  Validation Accuracy: 59.86%\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.5583  Validation Accuracy: 59.58%\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.5487  Validation Accuracy: 60.00%\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.5485  Validation Accuracy: 59.66%\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.5311  Validation Accuracy: 59.72%\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.5233  Validation Accuracy: 59.50%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2400  Validation Accuracy: 23.56%\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.0459  Validation Accuracy: 28.48%\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 1.9368  Validation Accuracy: 30.00%\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 1.8849  Validation Accuracy: 30.28%\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 1.8334  Validation Accuracy: 33.34%\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.8196  Validation Accuracy: 35.46%\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 1.7666  Validation Accuracy: 36.64%\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.6542  Validation Accuracy: 38.62%\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.6409  Validation Accuracy: 39.74%\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.6384  Validation Accuracy: 40.54%\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.6348  Validation Accuracy: 42.32%\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.6255  Validation Accuracy: 40.82%\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.5062  Validation Accuracy: 43.26%\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.5129  Validation Accuracy: 43.62%\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.5280  Validation Accuracy: 45.12%\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.5280  Validation Accuracy: 45.40%\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.5549  Validation Accuracy: 42.26%\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.4097  Validation Accuracy: 46.88%\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.4288  Validation Accuracy: 46.44%\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.4512  Validation Accuracy: 47.32%\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.4495  Validation Accuracy: 47.54%\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.4583  Validation Accuracy: 47.42%\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.3442  Validation Accuracy: 49.26%\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.3699  Validation Accuracy: 48.38%\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.3833  Validation Accuracy: 50.00%\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.3917  Validation Accuracy: 49.44%\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.3992  Validation Accuracy: 49.60%\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.2868  Validation Accuracy: 50.96%\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.3122  Validation Accuracy: 51.04%\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.3285  Validation Accuracy: 51.86%\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.3293  Validation Accuracy: 51.70%\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.3408  Validation Accuracy: 51.40%\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.2449  Validation Accuracy: 52.50%\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.2708  Validation Accuracy: 51.76%\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.2758  Validation Accuracy: 53.64%\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.2805  Validation Accuracy: 54.26%\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.3051  Validation Accuracy: 52.30%\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.2001  Validation Accuracy: 53.72%\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.2349  Validation Accuracy: 53.80%\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.2310  Validation Accuracy: 55.24%\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.2521  Validation Accuracy: 55.32%\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.2576  Validation Accuracy: 54.70%\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.1865  Validation Accuracy: 53.72%\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.1800  Validation Accuracy: 55.48%\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.1955  Validation Accuracy: 56.14%\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.2062  Validation Accuracy: 56.66%\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.2215  Validation Accuracy: 56.24%\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 1.1344  Validation Accuracy: 55.42%\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 1.1432  Validation Accuracy: 56.26%\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.1542  Validation Accuracy: 56.94%\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.1694  Validation Accuracy: 57.28%\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.1813  Validation Accuracy: 57.04%\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 1.1006  Validation Accuracy: 56.90%\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 1.1171  Validation Accuracy: 56.94%\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.1208  Validation Accuracy: 57.40%\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.1358  Validation Accuracy: 58.32%\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.1469  Validation Accuracy: 58.00%\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 1.0780  Validation Accuracy: 57.34%\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 1.0915  Validation Accuracy: 57.68%\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 1.0909  Validation Accuracy: 58.36%\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.1123  Validation Accuracy: 59.10%\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.1216  Validation Accuracy: 59.22%\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 1.0750  Validation Accuracy: 57.20%\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 1.0751  Validation Accuracy: 58.02%\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 1.0732  Validation Accuracy: 59.38%\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.0915  Validation Accuracy: 59.54%\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.1043  Validation Accuracy: 59.62%\n",
      "Epoch 14, CIFAR-10 Batch 3:  Epoch 14, CIFAR-10 Batch 4:  Loss: 1.0392  Validation Accuracy: 59.10%\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 1.0311  Validation Accuracy: 60.20%\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.0586  Validation Accuracy: 60.04%\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 1.0759  Validation Accuracy: 60.60%\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 1.0084  Validation Accuracy: 59.62%\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 1.0312  Validation Accuracy: 58.92%\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 1.0097  Validation Accuracy: 60.60%\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.0619  Validation Accuracy: 60.28%\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 1.0510  Validation Accuracy: 61.24%\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.9846  Validation Accuracy: 60.28%\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 1.0119  Validation Accuracy: 59.60%\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.9819  Validation Accuracy: 61.30%\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.0144  Validation Accuracy: 60.92%\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 1.0262  Validation Accuracy: 61.54%\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.9828  Validation Accuracy: 59.96%\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.9903  Validation Accuracy: 60.06%\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.9631  Validation Accuracy: 62.02%\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.0056  Validation Accuracy: 61.30%\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 1.0016  Validation Accuracy: 62.10%\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.9430  Validation Accuracy: 61.06%\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.9678  Validation Accuracy: 61.08%\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.9431  Validation Accuracy: 61.82%\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.9862  Validation Accuracy: 61.68%\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.9850  Validation Accuracy: 62.58%\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.9238  Validation Accuracy: 61.60%\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.9576  Validation Accuracy: 61.22%\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.9306  Validation Accuracy: 62.24%\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.9544  Validation Accuracy: 62.76%\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.9651  Validation Accuracy: 63.24%\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.9036  Validation Accuracy: 62.04%\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.9385  Validation Accuracy: 61.88%\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.9024  Validation Accuracy: 63.36%\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.9435  Validation Accuracy: 62.96%\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.9475  Validation Accuracy: 63.86%\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.8905  Validation Accuracy: 63.16%\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.9089  Validation Accuracy: 62.68%\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.8858  Validation Accuracy: 63.42%\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.9299  Validation Accuracy: 63.02%\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.9346  Validation Accuracy: 63.62%\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.8783  Validation Accuracy: 63.40%\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.8975  Validation Accuracy: 62.92%\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.8701  Validation Accuracy: 64.04%\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.9078  Validation Accuracy: 63.98%\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.9201  Validation Accuracy: 64.32%\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.8599  Validation Accuracy: 63.40%\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.8909  Validation Accuracy: 63.02%\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.8542  Validation Accuracy: 64.52%\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.8901  Validation Accuracy: 64.46%\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.9068  Validation Accuracy: 64.46%\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.8455  Validation Accuracy: 64.06%\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.8754  Validation Accuracy: 63.60%\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.8466  Validation Accuracy: 64.84%\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.8859  Validation Accuracy: 64.32%\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.8936  Validation Accuracy: 64.62%\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.8262  Validation Accuracy: 64.98%\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.8580  Validation Accuracy: 64.38%\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.8256  Validation Accuracy: 65.62%\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.8635  Validation Accuracy: 65.10%\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.8803  Validation Accuracy: 65.10%\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.8300  Validation Accuracy: 64.56%\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.8476  Validation Accuracy: 63.90%\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.8117  Validation Accuracy: 65.34%\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.8496  Validation Accuracy: 65.34%\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.8695  Validation Accuracy: 65.22%\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.8055  Validation Accuracy: 65.26%\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.8277  Validation Accuracy: 65.42%\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.7942  Validation Accuracy: 65.90%\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.8255  Validation Accuracy: 65.94%\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.8542  Validation Accuracy: 65.26%\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.7953  Validation Accuracy: 65.36%\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.8172  Validation Accuracy: 65.06%\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.7783  Validation Accuracy: 65.76%\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.8194  Validation Accuracy: 65.58%\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.8368  Validation Accuracy: 65.90%\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.7794  Validation Accuracy: 65.18%\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.7984  Validation Accuracy: 65.62%\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.7773  Validation Accuracy: 65.62%\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.7974  Validation Accuracy: 66.70%\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.8486  Validation Accuracy: 64.92%\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.7878  Validation Accuracy: 65.42%\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.7998  Validation Accuracy: 65.54%\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.7543  Validation Accuracy: 66.38%\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.7862  Validation Accuracy: 66.24%\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.8151  Validation Accuracy: 66.06%\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.7790  Validation Accuracy: 65.46%\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.7910  Validation Accuracy: 65.40%\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.7485  Validation Accuracy: 66.48%\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.7716  Validation Accuracy: 66.44%\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.8029  Validation Accuracy: 66.52%\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.7572  Validation Accuracy: 66.46%\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.7785  Validation Accuracy: 66.00%\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.7426  Validation Accuracy: 66.44%\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.7679  Validation Accuracy: 66.88%\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.8024  Validation Accuracy: 66.16%\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.7556  Validation Accuracy: 65.64%\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.7640  Validation Accuracy: 65.82%\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.7309  Validation Accuracy: 66.52%\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.7454  Validation Accuracy: 67.14%\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.7824  Validation Accuracy: 66.56%\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.7438  Validation Accuracy: 66.08%\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.7590  Validation Accuracy: 65.64%\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.7315  Validation Accuracy: 66.28%\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.7317  Validation Accuracy: 67.16%\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.7723  Validation Accuracy: 66.82%\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.7123  Validation Accuracy: 66.96%\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.7448  Validation Accuracy: 66.24%\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.7041  Validation Accuracy: 66.80%\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.7162  Validation Accuracy: 67.40%\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.7612  Validation Accuracy: 66.84%\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.7006  Validation Accuracy: 66.48%\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.7271  Validation Accuracy: 66.92%\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.6855  Validation Accuracy: 67.30%\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.7170  Validation Accuracy: 67.66%\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.7502  Validation Accuracy: 67.04%\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.7057  Validation Accuracy: 66.82%\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.7173  Validation Accuracy: 67.10%\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.7021  Validation Accuracy: 66.82%\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.7030  Validation Accuracy: 67.70%\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.7385  Validation Accuracy: 67.20%\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.6765  Validation Accuracy: 67.36%\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.7207  Validation Accuracy: 66.48%\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.6855  Validation Accuracy: 67.30%\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.6921  Validation Accuracy: 67.50%\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.7217  Validation Accuracy: 66.96%\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.6799  Validation Accuracy: 67.26%\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.7080  Validation Accuracy: 66.96%\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.6736  Validation Accuracy: 67.80%\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.6766  Validation Accuracy: 68.02%\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.7047  Validation Accuracy: 67.66%\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.6582  Validation Accuracy: 67.66%\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.6859  Validation Accuracy: 67.76%\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.6553  Validation Accuracy: 67.90%\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.6716  Validation Accuracy: 67.78%\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.7137  Validation Accuracy: 67.72%\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.6533  Validation Accuracy: 67.84%\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.6703  Validation Accuracy: 68.30%\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.6479  Validation Accuracy: 68.54%\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.6614  Validation Accuracy: 67.70%\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.7035  Validation Accuracy: 67.56%\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.6514  Validation Accuracy: 67.28%\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.6580  Validation Accuracy: 68.20%\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.6407  Validation Accuracy: 68.28%\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.6441  Validation Accuracy: 68.22%\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.6900  Validation Accuracy: 67.94%\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.6338  Validation Accuracy: 68.02%\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.6526  Validation Accuracy: 68.32%\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.6351  Validation Accuracy: 68.04%\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.6416  Validation Accuracy: 68.28%\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.6907  Validation Accuracy: 67.40%\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.6325  Validation Accuracy: 68.00%\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.6558  Validation Accuracy: 68.42%\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.6279  Validation Accuracy: 67.90%\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.6466  Validation Accuracy: 67.26%\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.6940  Validation Accuracy: 67.50%\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.6271  Validation Accuracy: 68.32%\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.6607  Validation Accuracy: 67.68%\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.6162  Validation Accuracy: 68.34%\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.6352  Validation Accuracy: 68.04%\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.6747  Validation Accuracy: 68.04%\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.5982  Validation Accuracy: 68.72%\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.6510  Validation Accuracy: 67.94%\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.5980  Validation Accuracy: 68.42%\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.6102  Validation Accuracy: 69.08%\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.6702  Validation Accuracy: 68.24%\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.5910  Validation Accuracy: 68.92%\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.6335  Validation Accuracy: 68.02%\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.5780  Validation Accuracy: 68.68%\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.6066  Validation Accuracy: 69.04%\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.6531  Validation Accuracy: 68.88%\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.5847  Validation Accuracy: 68.48%\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.6137  Validation Accuracy: 68.90%\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.5791  Validation Accuracy: 68.82%\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.5929  Validation Accuracy: 69.18%\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.6351  Validation Accuracy: 69.10%\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.5711  Validation Accuracy: 68.86%\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.5920  Validation Accuracy: 69.62%\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.5700  Validation Accuracy: 69.00%\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.5833  Validation Accuracy: 69.30%\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.6251  Validation Accuracy: 69.48%\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.5601  Validation Accuracy: 69.02%\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.5871  Validation Accuracy: 69.62%\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.5552  Validation Accuracy: 68.86%\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.5789  Validation Accuracy: 69.30%\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.6257  Validation Accuracy: 68.74%\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.5568  Validation Accuracy: 68.64%\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.5890  Validation Accuracy: 69.10%\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.5615  Validation Accuracy: 68.94%\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.5734  Validation Accuracy: 69.52%\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.6070  Validation Accuracy: 69.46%\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.5526  Validation Accuracy: 69.26%\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.5703  Validation Accuracy: 69.66%\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.5415  Validation Accuracy: 68.96%\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.5730  Validation Accuracy: 69.62%\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.6028  Validation Accuracy: 69.18%\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.5428  Validation Accuracy: 68.96%\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.5695  Validation Accuracy: 69.10%\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.5299  Validation Accuracy: 69.54%\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.5617  Validation Accuracy: 69.50%\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.5872  Validation Accuracy: 69.90%\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.5458  Validation Accuracy: 68.80%\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.5572  Validation Accuracy: 69.30%\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.5311  Validation Accuracy: 69.24%\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.5634  Validation Accuracy: 69.70%\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.5897  Validation Accuracy: 69.58%\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.5207  Validation Accuracy: 69.30%\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.5403  Validation Accuracy: 69.60%\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.5170  Validation Accuracy: 69.68%\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.5450  Validation Accuracy: 69.62%\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.5745  Validation Accuracy: 69.80%\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.5238  Validation Accuracy: 69.46%\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.5363  Validation Accuracy: 69.94%\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.5047  Validation Accuracy: 69.90%\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.5233  Validation Accuracy: 70.06%\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.5774  Validation Accuracy: 69.64%\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.5132  Validation Accuracy: 69.34%\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.5222  Validation Accuracy: 70.12%\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.5080  Validation Accuracy: 69.30%\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.5292  Validation Accuracy: 70.36%\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.5676  Validation Accuracy: 69.62%\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.5070  Validation Accuracy: 69.28%\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.5271  Validation Accuracy: 69.58%\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.4905  Validation Accuracy: 69.90%\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.5191  Validation Accuracy: 69.88%\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.5600  Validation Accuracy: 70.08%\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.5076  Validation Accuracy: 69.70%\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.5144  Validation Accuracy: 70.02%\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.4936  Validation Accuracy: 70.14%\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.5173  Validation Accuracy: 69.98%\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.5415  Validation Accuracy: 70.14%\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.4911  Validation Accuracy: 70.26%\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.5074  Validation Accuracy: 70.08%\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.4867  Validation Accuracy: 70.22%\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.5179  Validation Accuracy: 70.26%\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 0.5441  Validation Accuracy: 70.28%\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.4933  Validation Accuracy: 70.14%\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 0.4933  Validation Accuracy: 70.56%\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 0.4758  Validation Accuracy: 70.72%\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.4964  Validation Accuracy: 70.46%\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 0.5297  Validation Accuracy: 70.48%\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.4785  Validation Accuracy: 70.02%\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 0.4823  Validation Accuracy: 70.14%\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 0.4775  Validation Accuracy: 69.72%\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.5091  Validation Accuracy: 70.16%\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 0.5369  Validation Accuracy: 70.00%\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.4777  Validation Accuracy: 69.54%\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 0.4833  Validation Accuracy: 70.06%\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 0.4687  Validation Accuracy: 70.34%\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.4808  Validation Accuracy: 70.32%\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 0.5191  Validation Accuracy: 69.90%\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 0.4726  Validation Accuracy: 70.02%\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 0.4868  Validation Accuracy: 70.10%\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 0.4726  Validation Accuracy: 69.96%\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.4838  Validation Accuracy: 70.40%\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 0.5148  Validation Accuracy: 70.20%\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.4624  Validation Accuracy: 70.34%\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 0.4560  Validation Accuracy: 70.64%\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 0.4476  Validation Accuracy: 70.16%\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.4635  Validation Accuracy: 70.46%\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 0.5021  Validation Accuracy: 70.40%\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.4563  Validation Accuracy: 70.66%\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 0.4592  Validation Accuracy: 70.20%\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 0.4522  Validation Accuracy: 70.54%\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.4682  Validation Accuracy: 70.42%\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 0.5023  Validation Accuracy: 70.34%\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 0.4573  Validation Accuracy: 69.90%\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 0.4559  Validation Accuracy: 70.74%\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 0.4555  Validation Accuracy: 69.52%\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.4617  Validation Accuracy: 70.58%\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 0.5124  Validation Accuracy: 70.20%\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 0.4585  Validation Accuracy: 69.72%\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 0.4489  Validation Accuracy: 70.36%\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 0.4470  Validation Accuracy: 70.38%\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.4525  Validation Accuracy: 71.00%\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 0.4966  Validation Accuracy: 70.56%\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 0.4386  Validation Accuracy: 69.78%\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 0.4383  Validation Accuracy: 70.72%\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 0.4338  Validation Accuracy: 70.76%\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.4460  Validation Accuracy: 70.76%\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 0.4797  Validation Accuracy: 71.02%\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.4450  Validation Accuracy: 69.94%\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 0.4366  Validation Accuracy: 70.88%\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 0.4411  Validation Accuracy: 70.64%\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.4422  Validation Accuracy: 70.86%\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 0.4741  Validation Accuracy: 70.44%\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.4348  Validation Accuracy: 69.88%\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 0.4281  Validation Accuracy: 71.02%\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 0.4256  Validation Accuracy: 70.46%\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.4408  Validation Accuracy: 70.62%\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 0.4713  Validation Accuracy: 70.36%\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.4225  Validation Accuracy: 70.62%\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 0.4258  Validation Accuracy: 71.02%\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 0.4180  Validation Accuracy: 70.74%\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.4222  Validation Accuracy: 70.98%\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 0.4586  Validation Accuracy: 70.76%\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 0.3977  Validation Accuracy: 70.50%\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 0.4132  Validation Accuracy: 71.26%\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 0.4035  Validation Accuracy: 70.80%\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.4301  Validation Accuracy: 70.72%\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 0.4553  Validation Accuracy: 71.06%\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.4119  Validation Accuracy: 70.40%\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 0.4063  Validation Accuracy: 71.36%\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 0.4040  Validation Accuracy: 71.44%\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.4190  Validation Accuracy: 71.18%\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 0.4525  Validation Accuracy: 70.48%\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.3971  Validation Accuracy: 70.94%\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 0.4060  Validation Accuracy: 71.30%\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 0.3978  Validation Accuracy: 71.06%\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.4237  Validation Accuracy: 70.72%\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 0.4469  Validation Accuracy: 70.92%\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.4007  Validation Accuracy: 70.86%\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 0.3933  Validation Accuracy: 71.86%\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 0.3935  Validation Accuracy: 71.14%\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.4213  Validation Accuracy: 70.68%\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 0.4646  Validation Accuracy: 70.38%\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.4300  Validation Accuracy: 69.86%\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 0.4078  Validation Accuracy: 71.10%\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 0.4023  Validation Accuracy: 70.74%\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.4095  Validation Accuracy: 71.38%\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 0.4516  Validation Accuracy: 70.34%\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.3874  Validation Accuracy: 70.24%\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 0.4186  Validation Accuracy: 70.94%\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 0.3949  Validation Accuracy: 70.52%\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.3976  Validation Accuracy: 71.44%\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 0.4310  Validation Accuracy: 71.10%\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.3723  Validation Accuracy: 70.56%\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 0.4028  Validation Accuracy: 71.16%\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 0.3756  Validation Accuracy: 70.76%\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.4015  Validation Accuracy: 70.96%\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 0.4231  Validation Accuracy: 71.12%\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.3785  Validation Accuracy: 70.62%\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 0.3944  Validation Accuracy: 71.10%\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 0.3874  Validation Accuracy: 70.80%\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.3836  Validation Accuracy: 71.68%\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 0.4207  Validation Accuracy: 71.08%\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.3622  Validation Accuracy: 70.94%\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 0.3890  Validation Accuracy: 70.76%\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 0.3792  Validation Accuracy: 71.22%\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.4021  Validation Accuracy: 71.06%\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 0.4232  Validation Accuracy: 70.54%\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.3794  Validation Accuracy: 70.28%\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 0.3857  Validation Accuracy: 71.32%\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 0.3782  Validation Accuracy: 70.52%\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.3934  Validation Accuracy: 70.96%\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 0.4164  Validation Accuracy: 71.02%\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.3794  Validation Accuracy: 70.06%\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 0.3739  Validation Accuracy: 70.88%\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.3716  Validation Accuracy: 70.54%\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.3907  Validation Accuracy: 71.22%\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 0.4093  Validation Accuracy: 70.92%\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.3741  Validation Accuracy: 70.14%\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 0.3863  Validation Accuracy: 71.04%\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 0.3651  Validation Accuracy: 70.64%\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.3920  Validation Accuracy: 70.34%\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 0.3976  Validation Accuracy: 70.98%\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.3626  Validation Accuracy: 70.22%\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 0.3578  Validation Accuracy: 71.78%\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 0.3384  Validation Accuracy: 71.26%\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.3777  Validation Accuracy: 70.90%\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 0.4101  Validation Accuracy: 71.08%\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.3488  Validation Accuracy: 70.96%\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 0.3610  Validation Accuracy: 71.28%\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 0.3302  Validation Accuracy: 71.48%\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.3652  Validation Accuracy: 71.30%\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 0.3832  Validation Accuracy: 71.94%\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.3576  Validation Accuracy: 70.50%\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 0.3550  Validation Accuracy: 71.40%\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.3214  Validation Accuracy: 71.50%\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.3672  Validation Accuracy: 71.44%\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 0.3856  Validation Accuracy: 71.64%\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.3428  Validation Accuracy: 71.08%\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 0.3574  Validation Accuracy: 71.70%\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.3360  Validation Accuracy: 71.48%\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.3703  Validation Accuracy: 71.30%\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 0.3825  Validation Accuracy: 71.76%\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.3390  Validation Accuracy: 70.80%\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 0.3450  Validation Accuracy: 71.02%\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 0.3283  Validation Accuracy: 71.40%\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.3677  Validation Accuracy: 71.52%\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 0.3791  Validation Accuracy: 71.90%\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.3467  Validation Accuracy: 70.26%\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 0.3497  Validation Accuracy: 70.48%\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.3270  Validation Accuracy: 71.06%\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.3656  Validation Accuracy: 71.08%\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss: 0.3750  Validation Accuracy: 71.06%\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss: 0.3470  Validation Accuracy: 70.22%\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss: 0.3603  Validation Accuracy: 69.80%\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss: 0.3300  Validation Accuracy: 70.62%\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.3624  Validation Accuracy: 71.08%\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss: 0.3699  Validation Accuracy: 71.30%\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss: 0.3182  Validation Accuracy: 71.00%\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss: 0.3439  Validation Accuracy: 71.04%\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss: 0.3121  Validation Accuracy: 71.30%\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.3484  Validation Accuracy: 71.22%\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss: 0.3718  Validation Accuracy: 71.92%\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss: 0.3426  Validation Accuracy: 70.04%\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss: 0.3483  Validation Accuracy: 70.16%\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss: 0.3255  Validation Accuracy: 70.48%\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.3414  Validation Accuracy: 71.74%\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss: 0.3589  Validation Accuracy: 71.66%\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss: 0.3128  Validation Accuracy: 71.62%\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss: 0.3196  Validation Accuracy: 71.14%\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss: 0.2963  Validation Accuracy: 71.70%\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.3346  Validation Accuracy: 71.72%\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss: 0.3470  Validation Accuracy: 71.82%\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss: 0.3104  Validation Accuracy: 70.88%\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss: 0.3209  Validation Accuracy: 71.24%\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss: 0.3079  Validation Accuracy: 70.72%\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.3324  Validation Accuracy: 71.28%\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss: 0.3501  Validation Accuracy: 71.84%\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss: 0.3098  Validation Accuracy: 70.98%\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss: 0.3161  Validation Accuracy: 70.64%\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss: 0.3026  Validation Accuracy: 71.16%\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.3383  Validation Accuracy: 71.18%\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss: 0.3408  Validation Accuracy: 71.86%\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss: 0.3080  Validation Accuracy: 71.20%\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss: 0.3155  Validation Accuracy: 70.68%\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss: 0.2981  Validation Accuracy: 70.90%\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.3192  Validation Accuracy: 72.00%\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss: 0.3421  Validation Accuracy: 71.70%\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss: 0.2955  Validation Accuracy: 71.40%\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss: 0.3006  Validation Accuracy: 71.24%\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss: 0.2935  Validation Accuracy: 70.58%\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.3228  Validation Accuracy: 71.72%\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss: 0.3380  Validation Accuracy: 71.70%\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss: 0.2879  Validation Accuracy: 71.16%\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss: 0.3008  Validation Accuracy: 71.34%\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss: 0.2817  Validation Accuracy: 71.22%\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.3134  Validation Accuracy: 71.80%\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss: 0.3317  Validation Accuracy: 71.88%\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss: 0.2891  Validation Accuracy: 71.26%\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss: 0.2942  Validation Accuracy: 70.66%\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss: 0.2699  Validation Accuracy: 71.60%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.7085987261146497\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAIABJREFUeJzs3XecnGW5//HPtS29k4RAQhIJJXQIHYUg2AvYwA567L3+\n7EfQYznowQKe40FF7GBDPDZUBKSIdOmd0Amk182WuX5/XPfM8+yT2d3ZZLZ/36/XvGbmuctzT9nZ\na+65i7k7IiIiIiICDYPdABERERGRoULBsYiIiIhIouBYRERERCRRcCwiIiIikig4FhERERFJFByL\niIiIiCQKjkVEREREEgXHIiIiIiKJgmMRERERkUTBsYiIiIhIouBYRERERCRRcCwiIiIikig4FhER\nERFJFByLiIiIiCQKjgeZmc03s5eb2TvN7BNm9nEze6+ZvcrMDjaziYPdxu6YWYOZnWBm55vZfWa2\nzsw8d/nNYLdRZKgxswWFv5PT6pF3qDKzpYXHcOpgt0lEpCdNg92A0cjMpgPvBN4KzO8le8nM7gCu\nAH4PXOLurf3cxF6lx/BL4NjBbosMPDM7Dzill2wdwBpgBXAj8R7+mbuv7d/WiYiIbDv1HA8wM3sx\ncAfwH/QeGEO8RvsQwfTvgFf2X+v65If0ITBW79Go1ATsAOwJvBb4H+AxMzvNzPTFfBgp/O2eN9jt\nERHpT/oHNYDM7CTgZ2z9pWQdcCvwJLAFmAbsAiyuknfQmdnhwItyhx4CTgeuB9bnjm8ayHbJsDAB\n+CxwtJm9wN23DHaDRERE8hQcDxAz25Xobc0Hu7cBnwL+4O4dVcpMBI4BXgW8DJg8AE2txcsL909w\n938NSktkqPgoMcwmrwmYDTwTeBfxha/sWKIn+c0D0joREZEaKTgeOF8AxuTu/xV4qbtv7q6Au28g\nxhn/3szeC7yF6F0ebEtyt5cpMBZghbsvq3L8PuAqMzsL+DHxJa/sVDP7prvfPBANHI7Sc2qD3Y7t\n4e6XMcwfg4iMLkPuJ/uRyMzGAS/NHWoHTukpMC5y9/Xu/jV3/2vdG9h3s3K3Hx+0Vsiw4e6bgNcB\n9+QOG/COwWmRiIhIdQqOB8ZBwLjc/avdfTgHlfnl5doHrRUyrKQvg18rHD5uMNoiIiLSHQ2rGBg7\nFu4/NpAnN7PJwLOAnYEZxKS55cA/3f3hbamyjs2rCzN7BjHcYy7QAiwDLnX3p3opN5cYEzuPeFxP\npHKPbkdbdgb2Bp4BTE2HVwEPA/8Y5UuZXVK4v6uZNbp7Z18qMbN9gL2AOcQkv2Xu/tMayrUARwAL\niF9ASsBTwC31GB5kZrsBhwI7Aa3Ao8C17j6gf/NV2rU7cAAwk3hPbiLe67cBd7h7aRCb1yszmwcc\nToxhn0T8PT0OXOHua+p8rmcQHRrzgEbis/Iqd39gO+rcg3j+dyQ6FzqADcAjwL3AXe7u29l0EakX\nd9elny/AqwHPXf44QOc9GPgj0FY4f/5yC7HMlvVQz9Ieynd3uSyVXbatZQttOC+fJ3f8GOBSIsgp\n1tMG/DcwsUp9ewF/6KZcCfgVsHONz3NDasf/APf38tg6gb8Ax9ZY9w8K5c/pw+v/pULZ/+vpde7j\ne+u8Qt2n1lhuXJXnZFaVfPn3zWW5428iArpiHWt6Oe8ewE+JL4bdvTaPAh8CWrbh+TgK+Gc39XYQ\ncweWpLwLCumn9VBvzXmrlJ0KfJ74UtbTe/Jp4FzgkF5e45ouNXx+1PReSWVPAm7u4Xzt6e/p8D7U\neVmu/LLc8cOIL2/VPhMcuAY4og/naQY+TIy77+15W0N85jynHn+fuuiiy/ZdBr0Bo+ECPLvwQbge\nmNqP5zPgjB4+5KtdLgOmdVNf8Z9bTfWlssu2tWyhDV3+Uadj76vxMV5HLkAmVtvYVEO5ZcC8Gp7v\nN2/DY3Tgv4DGXuqeANxVKHdyDW16buG5eRSYUcf32HmFNp1aY7ltCo6Jyaw/7+G5rBocE38LnyOC\nqFpfl9tqed1z5/hkje/DNmLc9YLC8dN6qLvmvIVyLwNW9/H9eHMvr3FNlxo+P3p9rxAr8/y1j+f+\nOtBQQ92X5cosS8feS8+dCPnX8KQazjGT2Pimr8/fb+r1N6qLLrps+0XDKgbGDUSPYWO6PxH4oZm9\n1mNFinr7DvBvhWNtRM/H40SP0sHEBg1lxwB/N7Oj3X11P7SprtKa0d9Id53oXbqfCIYOAHbNZT8Y\nOAt4k5kdC1xANqTornRpI9aV3jdXbj61bXZSHLu/Gbid+Nl6HREQ7gLsRwz5KPsQEbR9vLuK3X1j\neqz/BMamw+eY2fXufn+1Mma2I/AjsuEvncBr3X1lL49jIOxcuO9ALe36OrGkYbnMTWQB9DOAhcUC\nZmZEz/sbCkmbicClPO5/EfGeKT9fewNXm9kh7t7j6jBm9gFiJZq8TuL1eoQYAnAgMfyjmQg4i3+b\ndZXadCZbD396kvilaAUwnhiCtC9dV9EZdGY2CbiceE3yVgPXpus5xDCLfNvfT3ymvb6P53s98M3c\noduI3t4txOfIErLnshk4z8xucvd7u6nPgF8Tr3vecmI9+xXEl6kpqf5FaIijyNAy2NH5aLkQu9sV\newkeJzZE2Jf6/dx9SuEcJSKwmFrI10T8k15byP+zKnWOJXqwypdHc/mvKaSVLzumsnPT/eLQko90\nU65SttCG8wrly71ivwN2rZL/JCIIyj8PR6Tn3IGrgQOqlFtKBGv5c72wl+e8vMTel9I5qvYGE19K\nPgZsLLTrsBpe13cU2nQ9VX7+JwL1Yo/bZ/rh/Vx8PU6tsdzbCuXu6ybfslye/FCIHwFzq+RfUOXY\nxwvnWpWex7FV8i4ELirkv5iehxvty9a9jT8tvn/Ta3ISMba53I58mdN6OMeCWvOm/M8jgvN8mcuB\nI6s9FiK4fAnxk/4NhbQdyP4m8/X9ku7/dqu9Dkv78l4Bvl/Ivw54O9BcyDeF+PWl2Gv/9l7qvyyX\ndwPZ58SFwKIq+RcD/yqc44Ie6n9RIe+9xMTTqu8l4tehE4DzgV/U+29VF1106ftl0BswWi5EL0hr\n4UMzf1lJjEv8DPAcYMI2nGMiMXYtX+8HeylzGF2DNaeXcW90Mx60lzJ9+gdZpfx5VZ6zn9DDz6jE\nltvVAuq/AmN6KPfiWv8Rpvw79lRflfxHFN4LPdafK1ccVvCNKnk+VchzSU/P0Xa8n4uvR6+vJ/El\n685CuapjqKk+HOdLfWjf3nQdSvEIVQK3Qhkjxt7mz/miHvJfWsh7dg1tKgbGdQuOid7g5cU21fr6\nA7N7SMvXeV4f3ys1/+0TE4fzeTcBR/VS/3sKZTbQzRCxlP+yKq/B2fT8RWg2XYeptHZ3DmLuQTlf\nO7CwD8/VVl/cdNFFl4G/aCm3AeKx0cEbiA/VaqYDLyTGR/4ZWG1mV5jZ29NqE7U4hehNKfuTuxeX\nziq265/AvxcOv7/G8w2mx4keop5m2X+P6BkvK8/Sf4P3sG2xu/8OuDt3aGlPDXH3J3uqr0r+fwDf\nyh060cxq+Wn7LUB+xvz7zOyE8h0zeyaxjXfZ08Dre3mOBoSZjSV6ffcsJP1vjVXcDHy6D6f8f2Q/\nVTvwKq++SUmFuzuxk19+pZKqfwtmtjdd3xf3EMNkeqr/9tSu/vJWuq5Bfinw3lpff3df3i+t6pv3\nFe6f7u5X9VTA3c8mfkEqm0Dfhq7cRnQieA/nWE4EvWVjiGEd1eR3grzZ3R+stSHu3t3/BxEZQAqO\nB5C7/4L4efPKGrI3E0uMfRt4wMzelcay9eR1hfufrbFp3yQCqbIXmtn0GssOlnO8l/Ha7t4GFP+x\nnu/uT9RQ/99yt2elcbz1dFHudgtbj6/ciruvA04mfsov+76Z7WJmM4CfkY1rd+CNNT7WetjBzBYU\nLovM7Egz+3/AHcArC2V+4u431Fj/173G5d7MbCrwmtyh37v7NbWUTcHJOblDx5rZ+CpZi39rZ6T3\nW2/Opf+Wcnxr4X6PAd9QY2YTgBNzh1YTQ8JqUfzi1Jdxx19z91rWa/9D4f7+NZSZ2Yd2iMgQoeB4\ngLn7Te7+LOBoomezx3V4kxlET+P5aZ3WraSex/y2zg+4+7U1tqkd+EW+OrrvFRkq/lxjvuKktb/U\nWO6+wv0+/5OzMMnMdioGjmw9WarYo1qVu19PjFsum0YExecR47vLvuLuf+prm7fDV4AHC5d7iS8n\n/8nWE+auYutgrif/14e8RxFfLst+2YeyAFfkbjcRQ4+KjsjdLi/916vUi/uLXjP2kZnNJIZtlF3n\nw29b90PoOjHtwlp/kUmP9Y7coX3TxL5a1Pp3clfhfnefCflfneab2btrrF9EhgjNkB0k7n4F6Z+w\nme1F9CgfTPyDOIDqX1xOImY6V/uw3YeuKyH8s49Nuob4SblsCVv3lAwlxX9U3VlXuH931Vy9l+t1\naIuZNQLHE6sqHEIEvFW/zFQxrcZ8uPvX06ob5S3JjyxkuYYYezwUbSZWGfn3GnvrAB5291V9OMdR\nhfsr0xeSWjUW7lcre1Du9r3et40orutD3loVA/grquYa2pYU7m/LZ9he6XYD8Tna2/OwzmvfrbS4\neU93nwnnAx/M3T/bzE4kJhr+0YfBakAio52C4yHA3e8gej2+C5WfhU8kPmD3K2R/l5l9z91vLBwv\n9mJUXWaoB8Wgcaj/HFjrLnMddSrXXDVXYmZHEONn9+0pXw9qHVde9iZiObNdCsfXAK9x92L7B0Mn\n8XyvJNp6BfDTPga60HXITy3mFu73pde5mi5DjNL46fzrVXVJvR4Uf5Woh+Kwnzv74Rz9bTA+w2re\nrdLd2wsj26p+Jrj7tWb233TtbDg+XUpmdivxy8nfqWEXTxEZeBpWMQS5+xp3P4/o+fhclSzFSSuQ\nbVNcVuz57E3xn0TNPZmDYTsmmdV9cpqZPZ+Y/LStgTH08W8xBZhfrJL04d4mnvWTN7m7FS5N7j7D\n3Xd395Pd/extCIwhVh/oi3qPl59YuF/vv7V6mFG4X9ctlQfIYHyG9ddk1fcQv95sKhxvIMYqv4vo\nYX7CzC41s1fWMKdERAaIguMhzMNniU0r8o4fjPbI1tLExR/TdTOCZcS2vS8gti2eSizRVAkcqbJp\nRR/PO4NY9q/o9WY22v+ue+zl3wbDMWgZNhPxRqL02f1FYoOajwH/YOtfoyD+By8lxqFfbmZzBqyR\nItItDasYHs4iViko29nMxrn75tyxYk9RX3+mn1K4r3FxtXkXXXvtzgdOqWHlglonC20lt/Nbcbc5\niN38Pk31XxxGi2Lv9F7uXs9hBvX+W6uH4mMu9sIOByPuMywtAXcGcIaZTQQOJdZyPpYYG5//H/ws\n4E9mdmhfloYUkfob7T1Mw0W1WefFnwyL4zIX9fEcu/dSn1T3otzttcBbalzSa3uWhvtg4bzX0nXV\nk383s2dtR/3DXXEM5w5Vc22jtNxb/if/XbvL242+/m3WorjN9eJ+OEd/G9GfYe6+wd3/5u6nu/tS\nYgvsTxOTVMv2A948GO0TkYyC4+Gh2ri44ni82+i6/u2hfTxHcem2WtefrdVI/Zk3/w/8SnffWGO5\nbVoqz8wOAb6cO7SaWB3jjWTPcSPw0zT0YjQqrmlcbSm27ZWfELtbmkRbq0Pq3Ri2fszD8ctR8TOn\nr69b/m+qRGwcM2S5+wp3/wJbL2n4ksFoj4hkFBwPD3sU7m8oboCRfobL/3NZZGbFpZGqMrMmIsCq\nVEffl1HqTfFnwlqXOBvq8j/l1jSBKA2LeG1fT5R2SjyfrmNq3+zuD7v7xcRaw2VziaWjRqO/0fXL\n2En9cI5/5G43AK+opVAaD/6qXjP2kbs/TXxBLjvUzLZngmhR/u+3v/52r6PruNyXdbeue5GZ7UfX\ndZ5vc/f19WxcP7qArs/vgkFqh4gkCo4HgJnNNrPZ21FF8We2y7rJ99PC/eK20N15D123nf2ju6+s\nsWytijPJ673j3GDJj5Ms/qzbnTdQ46YfBd8hJviUneXuv8nd/xRdv9S8xMyGw1bgdZXGeeafl0PM\nrN4B6U8K9/9fjYHcm6k+VrwezincP7OOKyDk/3775W83/eqS3zlyOtXXdK+mOMb+x3Vp1ABIyy7m\nf3GqZViWiPQjBccDYzGxBfSXzWxWr7lzzOwVwDsLh4urV5T9gK7/xF5qZu/qJm+5/kOIlRXyvtmX\nNtboAbr2Ch3bD+cYDLfmbi8xs2N6ymxmhxITLPvEzN5G1x7Qm4CP5vOkf7Kvput74Awzy29YMVp8\njq7Dkc7t7bUpMrM5ZvbCamnufjtwee7Q7sCZvdS3FzE5q798D1ieu3888LVaA+RevsDn1xA+JE0u\n6w/Fz57Pp8+obpnZO4ETcoc2Es/FoDCzd6YdC2vN/wK6Lj9Y60ZFItJPFBwPnPHEkj6PmtmFZvaK\nnj5AzWyxmZ0D/JyuO3bdyNY9xACknxE/VDh8lpl9xcy6zOQ2syYzexOxnXL+H93P00/0dZWGfeR7\nNZea2XfN7Dgz262wvfJw6lUubk38KzN7aTGTmY0zsw8ClxCz8FfUegIz2wf4eu7QBuDkajPa0xrH\nb8kdaiG2He+vYGZIcvebiclOZROBS8zsm2bW7QQ6M5tqZieZ2QXEknxv7OE07wXyu/y928x+Unz/\nmllD6rm+jJhI2y9rELv7JqK9+S8F7yce9xHVypjZGDN7sZn9ip53xPx77vZE4Pdm9rL0OVXcGn17\nHsPfgR/lDk0A/mJm/5aGf+XbPtnMzgDOLlTz0W1cT7tePgY8nN4LJ3a3jXX6DH4jsf173rDp9RYZ\nqbSU28BrJna/OxHAzO4DHiaCpRLxz3MvYF6Vso8Cr+ppAwx3P9fMjgZOSYcagI8A7zWzfwBPEMs8\nHcLWs/jvYOte6no6i65b+/5buhRdTqz9ORycS6wesVu6PwO4yMweIr7ItBI/Qx9GfEGCmJ3+TmJt\n0x6Z2Xjil4JxucPvcPdudw9z91+a2beBd6RDuwHfBl5f42MaEdz9SylYe1s61EgEtO81sweJLchX\nE3+TU4nnaUEf6r/VzD5G1x7j1wInm9k1wCNEILmEWJkA4teTD9JP48Hd/c9m9hHgv8jWZz4WuNrM\nngBuIXYsHEeMS9+PbI3uaqvilH0X+DAwNt0/Ol2q2d6hHO8hNsoo7w46JZ3/P83sWuLLxY7AEbn2\nlJ3v7v+zneevh7HEe+G1gJvZPcCDZMvLzQEOZOvl537j7tu7o6OIbCcFxwNjFRH8VltSahG1LVn0\nV+CtNe5+9qZ0zg+Q/aMaQ88B55XACf3Z4+LuF5jZYURwMCK4+5bUU/w3sgAIYH66FG0gJmTdVeMp\nziK+LJV9392L412r+SDxRaQ8Ket1ZnaJu4+qSXru/nYzu4WYrJj/grGQ2jZi6XGtXHf/WvoC83my\nv7VGun4JLOsgvgz+vUpa3aQ2PUYElPleyzl0fY/2pc5lZnYqEdSP6yX7dnH3dWkIzK/pOvxqBrGx\nTne+RfXdQwebEZOqixOriy4g69QQkUGkYRUDwN1vIXo6nk30Ml0PdNZQtJX4B/Fid39OrdsCp92Z\nPkQsbfRnqu/MVHY78VPs0QPxU2Rq12HEP7LriF6sYT0Bxd3vAg4ifg7t7rneAPwQ2M/d/1RLvWb2\nGrpOxryL6PmspU2txMYx+e1rzzKzbZkIOKy5+7eIQPirwGM1FLmH+Kn+SHfv9ZeUtBzX0cR609WU\niL/Do9z9hzU1eju5+8+JyZtfpes45GqWE5P5egzM3P0CYv7E6cQQkSfoukZv3bj7GuA4ouf1lh6y\ndhJDlY5y9/dsx7by9XQC8RxdQ9dhN9WUiPa/yN1frc0/RIYGcx+py88Obam3afd0mUXWw7OO6PW9\nHbgjTbLa3nNNIf5570xM/NhA/EP8Z60Bt9QmrS18NNFrPI54nh8DrkhjQmWQpS8I+xO/5EwlltFa\nA9xP/M31Fkz2VPduxJfSOcSX28eAa939ke1t93a0yYjHuzcwkxjqsSG17XbgTh/i/wjMbBfieZ1N\nfFauAh4n/q4GfSe87pjZWGAf4tfBHYnnvp2YNHsfcOMgj48WkSoUHIuIiIiIJBpWISIiIiKSKDgW\nEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEii4FhEREREJFFwLCIi\nIiKSKDgWEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEii4FhERERE\nJFFwLCIiIiKSKDgWEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEgy\n6oJjM1tmZm5mSwe7LSIiIiIytIy64FhEREREpDsKjkVEREREEgXHIiIiIiKJgmMRERERkWRUB8dm\nNt3MzjSzB81si5k9ZmbfMbM5PZQ51sx+bWZPmllbur7QzJ7dQxlPlwVmttjMfmBmj5hZu5n9Jpdv\nlpl9xcxuM7ONZtaa8l1tZp8zs/nd1D/TzL5kZrea2YZU9jYz+4KZTd++Z0lERERk9DB3H+w2DCgz\nWwbMB94A/Ee6vQloBMakbMuAg9x9daHsfwCfSncdWAtMASwd+7K7f6LKOctP8huBbwPjgfVAM3Cx\nu5+YAt9/AOXAvBNYB0zN1f9Od/92oe5nAhcB5SC4DSgBY9P9R4DnuPvdPTwtIiIiIsLo7jk+C1gN\nHOnuE4CJwAnAGmAB0CXINbNXkwXGZwOz3H0aMDPVBfBxM3t9D+f8b+A6YF93n0wEyR9OaZ8lAuP7\ngKOBFnefDowD9iUC+ScLbZoP/B8RGP8PsFvKPyGV+TMwD/i1mTXW8qSIiIiIjGajued4ObC3u68s\npH8Y+CrwoLs/Ix0z4B5gEXC+u7+mSr0/BV5D9Drv6u6lXFr5SX4A2MfdN1cpfwewGHi1u19Q42P5\nMfA6uu+xbiGC8f2AV7n7L2upV0RERGS0Gs09x+cUA+OkPAZ4oZlNSLcPIAJjiB7cak5P1wuAQ7vJ\nc3a1wDhZl667He+cZ2bjgVcRQyjOrJbH3duAckD8nFrqFRERERnNmga7AYPoum6OP5a7PRXYCByU\n7j/t7rdXK+Tud5vZY8DOKf81VbL9o4f2/AE4DPhPM9uNCGqv6SGYXgK0EGOfb43O7arGpet5PZxb\nRERERBjdPcfrqx1099bc3eZ0PTNdP0bPHi3kL3q6h7L/CfyWCHjfBfwNWJdWqviomU0t5C/3MBsw\nu4fL5JRvfC9tFxERERn1RnNwvC3G9p6lR53dJbj7Fnc/ATgCOIPoefbc/XvMbP9ckfJrt9bdrYbL\n0u1su4iIiMiIp+C4NuUe396GJswt5O8zd7/G3T/m7kcA04hJfg8TvdHfzWVdnq4nm9mUbT2fiIiI\niGQUHNfmxnQ9wcyqTrYzs92J8cb5/NvF3Te6+/nA29KhJblJgtcDHcSwiufX43wiIiIio52C49rc\nTKw/DPDJbvKclq6XAdf29QRp2bXulCflGTEmGXdfD/wqHf+cmU3qoe4mM5vY1zaJiIiIjDYKjmvg\nsRj0p9PdE8zsLDObAWBmM8zsm8TwB4BP59c47oPbzOyLZnZIOVC2cCjZJiPXFXbt+ziwCtgduNrM\nnm9mzbmyu5nZh4C7gIO3oU0iIiIio8po3gTkWHe/rJs85Sdlobsvyx3Pbx9dIts+uvwlo7fto7vU\nV8izJtUFMXFvLTCJbMWMFcBx7n5LodwhxNrMO6VD7cSayZNIvczJUne/vNq5RURERCSo57gP3P3T\nwHHARUSwOhFYSSzBdny1wLgPTgC+BFwFPJ7qbgNuAb5M7OZ3S7GQu18H7Al8DLga2ECsz7yJGJf8\nTeAYBcYiIiIivRt1PcciIiIiIt1Rz7GIiIiISKLgWEREREQkUXAsIiIiIpIoOBYRERERSRQci4iI\niIgkCo5FRERERBIFxyIiIiIiiYJjEREREZFEwbGIiIiISNI02A0QERmJzOxBYDKwbJCbIiIyXC0A\n1rn7woE86YgNjscueoEDjBnXWDnWNCa2yh47thmAjY8tr6RtWrkSADMDoLNtSyWtssX2uHEAtIwf\nW0mzUmfk37gRgMaOzqwRFuU6OtoAKJU6srY0NaS09sqxzs50Hktttqxjv2nMuFQu2t7R2lpJa2gZ\nA8CE6VMAWLDHvEravEU7A7DFog1NDaVK2qM33wfAzVdcYYhIvU0eN27c9MWLF08f7IaIiAxHd955\nJ5s3bx7w847Y4Li0MeK99ra2yrE24glesM/uAKxuzQLF1k2RNnFiBKENZGlrV68CoGNLBLKdeCWt\nZVxLnC8F0N6ZBcBUAtEImN2zQLgcQ5c8F0w3RDBs5VA1F7J2ltLj6Ij6m5uyl64cVG9auwmA+257\noJK2cmW0fY/9FwGwau2qStpdt9yFSL2Y2QLgQeAH7n7qoDZmaFi2ePHi6TfccMNgt0NEZFhasmQJ\nN95447KBPq/GHIuIiIiIJCO251hEZLDd9thaFnz894PdDBGRQbHsyy8a7CZskxEbHDd2xrjdhtyw\nhfa2GJIwa9w0AHbdNxub++DkqQC0dcTwiuVPPlJJmzBpPAAdY2P4wuaObKhGKY1pNo/hFW0rN2aN\naC8PsYjhFSXPhmpYKW5XxjMDjY1RV8uYGEPc3p61vWlMjDX2VK6jNWvDmPEx1rhx3AQAWtuy8cgr\nVqwBYPwDD0cey4Z9dLblhoCIiIiIiIZViEj9mdkCMzvfzFaYWauZXW9mL66Sb4yZfdzMbjWzTWa2\nzsyuMLOTuqnTzew8M9vdzC4ws6fMrGRmS1OeZ5jZOWZ2n5ltNrNVqe5vm9mMKnW+xswuNbM1qZ13\nmtmnzWxMvzwxIiIy5I3YnuPO9ugBzk+CK7VGT+kdN9wBwOGHH1xJO+qAQwC45rorAWhqz8q1pxUl\nUqctLZPGVdImzY6J6FtWRw9t66qVlbSGtNpEY2P0+tKRrYBRnsDX0JC9BE1N0ftsabWKhqZspY3y\nsVLqaG5sydLGT5kEwITp0Zb2hqztLWlhDfN47Bs3r6+k0ZD1WovU0XzgWuAB4EfAdOBk4CIzO97d\nLwUwsxY1PcuaAAAgAElEQVTgYuAY4C7gW8B44JXABWZ2gLt/skr9uwL/BO4BfgKMA9aZ2RzgOmL5\ntD8AvwLGAguBNwBnA5U/UDM7F3gT8GjKuwY4HPg8cJyZPcfd9fOKiMgoM2KDYxEZNEuB09z99PIB\nM/sp8Cfgo8Cl6fCHicD4j8BLy4GomZ1OBNefMLPfufvVhfqfCXypGDib2XuJQPwD7v6NQtoEyJag\nMbNTicD4QuB17r45l3Ya8Fng3UCXeqoxs+6Wo9izt7IiIjL0jNjguKExxuR2bs56a8vdrqufjl7e\nx+9bVknasmoFALYp8r/lDadU0laufhqAi377hyiX6x2eMDnGIzemnuAmy3p0S+l8DeUe4aZsbbb2\n9tSuXOdtU2P8ktuZhhrnhijTlpaIKw9RHjs++9W30yLjxtZ1AMxfvEslbfyEaM/0yTEeecWqpypp\nO07dAZF+8BDwH/kD7n6xmT0MHJo7/GbiL+BD+R5ad3/KzD4PfBd4C1AMjpcDp9O9rRbFdPeNhUPv\nBzqAN+cD4+TzwHuA11FDcCwiIiPLiA2ORWTQ3OyeX8C74hHgCAAzmwQsAh5z92oLbv8tXR9YJe1f\n7r6lyvHfAl8EvmVmzyOGbFwF3OG5ma9mNh7YH1gBfMCs6h44W4DF1RKK3H1JteOpR/mgWuoQEZGh\nQ8GxiNTbmm6Od5BNAp6Srp/oJm/5+NQqaU9WK+DuD5nZocBpwPOBl6ekR8zsq+7+zXR/GrHFzkxi\n+ISIiEjFiA2OGyw6lto7s8lplNIQgx3i//IbT3lpJWnqxIkAXHvtPwHYdadZlbQle8fQwR2mzATg\n17/L1i1d9sSjAGxui93pxowfX0lr35DOXYqeqYaGlkramLTDXVtb9ovultZ0O03S6yxlPVrNqd6m\n5ngMWzauraS1pa2uO9JW1tN2yNqw0467ArBg4XwA9jxgj0qat+WeG5GBVX4D79hN+pxCvrxuZ5K6\n+53AyWbWRPQOHw+8F/iGmW109+/l6rzJ3dWzKyIiXYzY4FhEhi53X29m9wPPMLPd3P3eQpZj0/WN\n21h/B3ADcIOZXQ38HTgR+J67bzCz24G9zWy6u6/qqa7tsc/OU7hhmC6CLyIyWo3Y4Lh9U5p/483Z\nQY9fdA9cshcAxzznkErStVfcBEBnmih38z+vqqRNnzIbgGmzYqLbvJnZ5iG7zo+e2SdXxy+9t9x+\nUyWtM/XkjkuT5xqas8l6jUSvcEtb9hKs3xD/o708qT7X09y2JTb2aBkba7ONbbFcWpynKeV//N6H\nKmnrVsav07ddfzMAi/bfvZI2e2G1X6xFBsy5wBeAr5jZK8rjlM1sB+AzuTw1MbMlwH3uXuxtnp2u\nN+WOnQl8DzjXzE519y5DQcxsGrDQ3bcpOBcRkeFrxAbHIjLkfRV4AXAC8C8z+wOxzvGrgFnAGe5+\nZR/qewPwdjO7ErgfWE2sifwSYoLd18sZ3f3cFEy/C7jfzC4GHiaWglsIHA18H3jHdj1CEREZdhQc\ni8igcPc2M3sO8CHgtcTY4A7gX8RaxT/rY5U/A8YARwJLiM1BHgPOB/7L3W8rnP/dZvZHIgA+npj8\nt4oIkr8C/HgbH5qIiAxjIzY4bmqI4RQduak7HaW0VnDa6u7qq/5VSTv9M18BYN9FCwGYPS0bjtG6\nMiaurb01Jt8tu+O+Stpxz4uhkSe84LkA3HbXPpW0X/72IgAee2o5ABPGTKqkjR0TQy1aPNttb2Jj\nDIuYPi0mA06Ykg172NS+AYB1G2ON5ac2baikWVMMF2kaE+U996puaY22r3kqhlds2JwtnryY+YjU\ni7svA6qui5bSl1Y51kosv/bFOtT/T2LnvJq5+++A3/WljIiIjGwNvWcRERERERkdRmzPsadl2+iy\nF0H0HM+YHj24d9/1YCXl0eWxQ94+C2PC2qpV6yppje3RWdVssQRc68r1lbRbron5OpOa43vGC48/\nppI2b3bsQHfJ3y8DYEtH1paxzTGxrrS5sjEYpXXRzT1tWpo/1JK9PGMmxO1Z86LOG+7I5gn947qY\nBNialq0b1zKhkmZp86/WtTHfaMLkmZW0lY8XNw0TERERGd3UcywiIiIikozYnuMtm7beXbapIXqT\nx49L432bsqXV5qTe2vL43XsfzHqVd5g0HYAFM2YA2QYeAKtXx6pRl//58jjH5mxTj+e84EgAZj83\nxhWvWZetJGWlOM+ap7MVpB5+9GkAVq6OfPffc3/W+ObovX7ZbicA8JEPfLSSdMlllwJw/q9+BUDD\n2Kx9mza0xQ2P6y2bs/M98UgbIiIiIpJRz7GIiIiISKLgWEREREQkGbHDKsaMiUlpjZat5dbUELf3\n2D2Wa5s+eXwlbddFOwGwsSMm2z341COVtE3tMdFtYnNM5NtcyoZHdLTHU9i+OYYoXHtVNlFu0YIY\nhjFlh1iS7eEnn66kTWiJuiY1jc3asNuCuE7nufvhRytp9z4Qu961/yJWnZo7f8dK2mtf+SoANqyP\nSYTX33xzJe2eJ2PnvsamWOZt3KRsUuA+B0xDRERERDLqORYRERERSUZsz/HMGbFkWVMu/G9sjF7T\n+fOjl3jT2qwnd8XKxwDwxpik11rKNst4cm0s8+Zb4tiajtzEuvVR5w7jo3d4/ab2StrVaZm3JYce\nBMDjT6yopLVtjI1Bpk7Oem/HzYoe4x3nRq/wwvkLKmkPPxE9wMseih7t//3W9yppL33p8wCYMy3a\nsGnNqqx9aUk7t9jUZO68yZW0JQfNQ0REREQy6jkWEREREUlGbM/xqtXRM0vWAczkSTHutlSK3t25\ns2dX0qZMmgjA7ffF2F73bPvozW2xWcYjbdFL7LRU0sqLwY1rj+XhVnVmY5yvu/EeAFasbwVg3bps\n040Nq2PJtxlTdqgcm794FwDa2+JlGZ9bam7WjGjfw0/HNtB33vlQJa1tQ2xT/bznRQ+15Xq2x42L\ncdV7HrgorvfLNgjZZaZ6jkVERETy1HMsIiIiIpIoOBYRERERSUbssIrNm8tDGLKly2bPmAVA6/rY\nJW6LTamkTZsWE9XWbVwdBxqyciXviOtKXdlYDYuN62hti6EaTeUDwJYtsbzbin/dFnkbs2ESpS2R\n76lV67L8LVHv+DRxb+WqtZW0ceNjybdSKdrSnmvDk0/ExMK777w3zuNZGzZviedh7PjIv6UtO98D\n9zyAiIiIiGTUcywiQ4qZLTOzZYPdDhERGZ1GbM9x88S0yUZL9hB3mBGbctx5250AXLchm7i2ckNs\n/jF2YvTQbtmyOausFJPzLH2XcLKe2fL0u06PW50NubSG6Cle1xZ1d1rW29tYntTXvqVybOP9MYFv\n8oRYkq2zI+u9bpmc8jem83RkS8ZNnDQ9yqeNSFauXlNJW78+HuOyh6JX2ZuyCXmrn87yiYiIiIh6\njkVEREREKhQci4iIiIgkI3ZYxfx9FwJgrbk1f6fGWsGPrY8d5Frbs2ELk+fHZL0p62InupWPZ2l0\npuEUntY5ThP0AEppiEUbW1LWbH3kxpYo19Ye+beU2ippRlu6zl6CzZujjk3tkdbSlKU1p8l8nbSm\nctkQjcnT4nF1lKJ9a9ZlE/maxsb6y8/Y/RkAzJ2f7ZDXtilbk1lkIJmZAe8G3gnsCqwELgQ+1UOZ\n1wBvAw4ExgIPAj8BvuLuW6rk3xP4OHAcMBtYDVwCnO7udxfyngecktryIuCtwG7AP9196bY/UhER\nGW5GbHAsIkPa14H3AU8A5wDtwAnAYUAL0JbPbGbnAm8CHgV+BawBDgc+DxxnZs/x3LdWM3s+8Gug\nGfg/4D5gLvBy4EVmdqy731ilXd8AngX8HvgD+eVuumFmN3STtGdvZUVEZOgZscHx3APGAdC+Mfvf\nNn1yTEbbNCF6k705G1Uydnr0xB6wQ+wkd+fVWc/sQ7c9DkAD5f+9WVrJ43Zbut7UkfXGNrbE5D4s\n2tBJ1rlllSXf8i9B3PbOcp25yX3ro2wHm1Jbsthh5Zro7e70eDxb2rOd+ObttjMAex4QPcdTZ2S7\n+02dMAuRgWZmRxKB8f3Aoe6+Kh3/FHApMAd4KJf/VCIwvhB4nbtvzqWdBnyW6IX+Rjo2DfgZsAk4\n2t3vyOXfB7gG+C5wUJXmHQQc6O4P1ufRiojIcKMxxyIy0N6Urr9QDowB3L0V+ESV/O8HOoA35wPj\n5PPEkIzX5Y69EZgKfDYfGKdz3AZ8BzjQzPaqcq4z+hoYu/uSahfgrr7UIyIiQ8OI7TledFCMtZ06\nOesdnZZuL386dUplnahMmBgbguw4PpZ7mzVpTCXtJ3fdB0Bne7nHOOvRLfcid6br1s6sp9o2xv/x\nkremA1lvb6V/OTd+GYtzdjZEXR2duWGUHmXd2tNZs3LWFMda21I5z9qwYNFsAA5fug8ATWOzNkwa\nOwORQVDusb28StqV5IYymNl4YH9gBfABM6tShC3A4tz9I9L1/qlnuWj3dL0YuKOQdm1PDRcRkZFv\nxAbHIjJklbemXF5McPcOM1uROzSN+DY6kxg+UYvyt7639pJvYpVjT9Z4DhERGaE0rEJEBlp5OZXZ\nxQQzawJ2qJL3Jne3ni5VyuzfS5kfVGmblnARERnlRmzP8fMOPxCA9vbc8mkW3wUW7RS/qnru0bd3\nxv/EFmLJtOOff2gl7darbwfgxqtjZ72mxvzTFnWW0jJqufl4tKehDw1N0YbGUm6CXcrXkNs1r9LO\nphhOMX5aY+XYhnXpl+aOOHcpNynQU/6NbZG/oSErt8uCmJg4b250knV6trMepV4n4ov0hxuJoRXH\nAA8U0p4JVN7A7r7BzG4H9jaz6fkxyj24BngFserELfVpsoiIjBbqORaRgXZeuv6UmU0vHzSzscCX\nquQ/k5ghcK6ZTS0mmtk0M8uvPPF9Yqm3z5rZoVXyN5jZ0m1vvoiIjGQjtud4ckv0mLblJs+ZRXdt\nY1rCLf9DbEfqbS1vrjFj5+x/8B57xfJuN11zT+RpyLqHS2nvAU/naWgYn6Wl+ttLaRJdfjKRN6Zj\nWU/u+Emx9NszjzsMgEW7L6ik/eTcXwGwenks5dbYkM0mXLNuHQAbN0Xbp8zK2r773vPT44rzNFn2\nfaixecS+/DKEuftVZnYW8F7gNjP7Jdk6x6uJtY/z+c81syXAu4D7zexi4GFgOrAQOJoIiN+R8q80\ns1cSS79dY2aXALcTQybmERP2ZhAbiYiIiHSh6EhEBsP7gXuI9YnfTrZD3ieBfxUzu/u7zeyPRAB8\nPLFU2yoiSP4K8ONC/kvMbD/gI8DziCEWbcDjwN+IjURERES2MmKDY2+M3t2msdl2zuWe40oPcq5X\nudHiqWhoiHG4Yywbt7vDzGmpXNyfPTdbAm3XPeYCcMuNMR559VOtubQY2zx3UWzZvHLdykpaQxrw\nPH1GNmF+8UHRQ33U0vgleOLYSZW0a6++Ka6XR9wwpinbBnpMy6RUf3S47bbbwkraLnuk2+Uxzg25\nx9ygUTUyONzdgbPTpWhBN2V+B/yuD+dYBrynxrynAqfWWreIiIxcio5ERERERBIFxyIiIiIiyYgd\nVtHYGMMHOtqz5co609JljWloQWND9vAb0piJUnl3udxudtNnxBAGS8MQFu4+t5L20c++A4Df/vIv\nAJzzXz+spO2yaCYA7/7YSXH+pmzHu/IwjrFjsmEOLZPTMm0WS8A1eza044AlsdPttZfHsAojGy7S\n3BSTAMdNjPbtsd8ulbSZc2IxAC9tSeVy34dMS7qKiIiI5KnnWEREREQkGbE9x01epVc09Q6nTmUa\nS1keT72oJdJmHp3ZxLrJU6Nnduz4WPlpysxsubaJs6KyAw9fDMC4SdlEuXUbYhfclnHRCz15Vrb8\nWvl7SUOpo3KkrSOd01IPd1OW/5Aj9gHgd/NmAfD0o1nP9pYtcXvhgpgoeOjB2YS88ekVLqUe9IaW\nXI9zY9YzLSIiIiLqORYRERERqVBwLCIiIiKSjNhhFZPHxdCHjvZs+EHJYwhDeanfhlL23aAjrWvc\nkCbKNTdmT83EyWnC24S4XrBbNiHPxsREtxk7xlrDc3beqZLmnVFno8VQhvz8t3IbLLfW8sTm2NWv\nsyHtqEc2mXD3xfMA2P/gPQH4y6M3VdKamuJxHH5YTNo7cO95lbTxab3nDhsTbWnKHpfWORYRERHp\nStGRiIiIiEgyYnuOG1LPb3NuR7hSWhqtlCbBlTrzk/ail7bcu1teag2yiXLNY6L83LmzsmKprilT\nY6e73fdeUEl6/KGYkNfWXooDlt+tL243NrZnx8q72KW0jo5SJS11hLP3vtFrfeWfbq+k7TxvNgBH\nHXMQALNnZZMCm1tiEmGHRV1OVqdZdltERERE1HMsIiIiIlIxYnuOOzrL43Wz3mGztHxa6lVuyy3X\n1tmZenBTb3Jjbsyxd8S44gnjovzOs6ZX0sY1RC/vmEkTAFi8z/xK2v13PQzAhnXrAZg1b0ZWZ/k8\nTVnPdrmnuLMyFjpbaq25JdL2WrwzAJMnZu2bMiPGE8/fI9I8/5WnMy1fV66qIest7uzsQEREREQy\n6jkWEREREUkUHIvIkGFmC8zMzey8GvOfmvKfWsc2LE11nlavOkVEZPgYscMqxjXEOIKOjmwpN/eu\nQy1acsuoWWUYhXcpDzAujUmYs0Ms17bjjGzC25g04a88f2+3BdlkvaZSDNuwts5UZzYhr5Ta0phb\nTs5SJeV2NjZmQ0Ia065583eZA8DSZx9USZsyKyYD7rTzzHRkXdaGhtSw9BhymwJSQsMqRERERPJG\nbHAsIqPChcA1wBOD3RARERkZRmxwPKE5emm3lDq3Tkwdxp25btTOjsjXlHpY873Kk8a0AHDgvrsB\nMGPK+Kyutpis19wYPdQH7rewknToQbFhR7PH09xiWZ3liXFWynqTGxvjdgNRV8mzXu+G1NSJ42Oj\nkBefcGwlzcdsjrY3pQ0/OrJe7/KydU2pZ7zkWRsqvcoiw5S7rwXWDnY7RERk5NCYYxEZksxsTzP7\njZmtMrONZnalmT23kKfqmGMzW5Yuk83szHS7PT+O2Mxmm9n3zGy5mW02s5vN7JSBeXQiIjJUjdiu\nwwZPm150ZJtslDfAsLTbRmNuP2f3uF1Ky5u5ZeVmz4yl25597BEATBw/ppJWSuOCPfVQz9lxSiVt\nyZLoOd6yKS0Z15n1YptFr3BTQ1ZXuY6GlNaQ26SjoSO+x3S2xrE9ds96qMfOiLZubt0IQHNjrufY\n0+NIvddNuc1NSq5NQGTIWgj8A7gV+F9gDnAy8Ecze627X1BDHS3A34DpwJ+JwfgPApjZDsDVwDOA\nK9NlDvDtlFdEREapERsci8iwdjTwVXf/aPmAmZ1NBMzfNrM/uvu6bkuHOcAdwDHuvrGQ9kUiMP66\nu3+wyjlqZmY3dJO0Z1/qERGRoUHDKkRkKFoLfC5/wN2vB34CTAVeVmM9Hy4GxhZ7t78OWA+c1s05\nRERklBqxPcdtbTGUoa19S+VYyWPIRCkNXyiRDXNoTEuytaRJcR2lbJkzS0Mnpqcl3Mo72QF0pkl2\n5WluDc1ZObdowxNPPJXaMjuXtgGAcY3Z5D5L7WlMwyraO3LDMNpiqETrxmjLjJ2y5eSaxqyJtqSh\nF+WdAONE6TGnNje3ZC95o74aydB1o7uvr3L8MuAU4EDgB73U0QrcUuX4nsB44Io0oa+7c9TE3ZdU\nO556lA+qliYiIkOXwiMRGYqWd3P8yXQ9pZv0vKe8PJmgq3LZ3s4hIiKj0IjtOW5tTxPRGrL4v7kx\nJr+1t0fPrOW+G1ja/KO8ulupI1vy7PprbgVgbEsso/bchUdU0jrSJDtPvbWl3NJxM2ftAMC/brsX\ngLb2bGm2pubGdGxT1oa0vFtDed22UtZD3bYpbt/5rwcAmD5150rajJmptzttMmL5eCBNwGtI1525\nfT/yK8uJDDGzuzm+Y7quZfm2aoFxvmxv5xARkVFIPcciMhQdZGaTqhxfmq5v2o667wI2AQeYWbUe\n6KVVjomIyCih4FhEhqIpwL/nD5jZwcREurXEznjbxN3biUl3kyhMyMudQ0RERqkRO6yiIQ0xyI8w\nKA8/bEqT7lqast3pyksQe5qIt2VdVnDZ7SsA2HP/eSlvNk/I0jrCDQ0xsW7T5tZKWpNF/WPTDntd\nRjF45O/wTbn8kc+J63EtLZW0a268C4Bbr78HgL3Sbn0Ak+fEOswdpTh3Y+47T0ua8GepLZ25tZZL\nJa1zLEPW34G3mNlhwFVk6xw3AG+vYRm33nwSOA74QAqIy+scnwz8AXjpdtYvIiLD1IgNjkVkWHsQ\neAfw5XQ9BrgR+Jy7X7y9lbv7CjM7iljv+CXAwcDdwDuBZdQnOF5w5513smRJ1cUsRESkF3feeSfA\ngoE+r1WfzC0iItvDzLYAjcC/BrstMmqVN6K5a1BbIaNVPd5/C4B17r6wt4z1pJ5jEZH+cRt0vw6y\nSH8r796o96AMhuH8/tOEPBERERGRRMGxiIiIiEii4FhEREREJFFwLCIiIiKSKDgWEREREUm0lJuI\niIiISKKeYxERERGRRMGxiIiIiEii4FhEREREJFFwLCIiIiKSKDgWEREREUkUHIuIiIiIJAqORURE\nREQSBcciIiIiIomCYxGRGpjZXDM718weN7MtZrbMzL5uZtP6WM/0VG5ZqufxVO/c/mq7jAz1eA+a\n2WVm5j1cxvbnY5Dhy8xeaWZnmdkVZrYuvV9+vI111eXztL80DXYDRESGOjPbFbgamAVcBNwFHAq8\nH3i+mR3l7itrqGdGqmd34G/A+cCewJuAF5nZEe7+QP88ChnO6vUezDm9m+Md29VQGck+DewPbAAe\nJT67+qwf3st1p+BYRKR3/018kL/P3c8qHzSzM4EPAl8A3lFDPV8kAuMz3f3DuXreB3wjnef5dWy3\njBz1eg8C4O6n1buBMuJ9kAiK7wOOAS7dxnrq+l7uD+bug3l+EZEhLfVy3AcsA3Z191IubRLwBGDA\nLHff2EM9E4GngBIwx93X59IagAeA+ekc6j2Winq9B1P+y4Bj3N36rcEy4pnZUiI4/om7v74P5er2\nXu5PGnMsItKzY9P1n/Mf5AApwL0KGA8c3ks9hwPjgKvygXGqpwRcXDifSFm93oMVZnaymX3czD5k\nZi8wszH1a65It+r+Xu4PCo5FRHq2R7q+p5v0e9P17gNUj4w+/fHeOR/4EvBfwB+Ah83sldvWPJGa\nDYvPQQXHIiI9m5Ku13aTXj4+dYDqkdGnnu+di4CXAHOJXzL2JILkqcAFZqYx79KfhsXnoCbkiYiI\njBLu/rXCobuBT5rZ48BZRKD8pwFvmMgQop5jEZGelXsypnSTXj6+ZoDqkdFnIN473yWWcTsgTYwS\n6Q/D4nNQwbGISM/uTtfdjYHbLV13N4au3vXI6NPv7x13bwXKE0UnbGs9Ir0YFp+DCo5FRHpWXsvz\nuWnJtYrUw3YUsAm4ppd6rgE2A0cVe+ZSvc8tnE+krF7vwW6Z2R7ANCJAXrGt9Yj0ot/fy/Wg4FhE\npAfufj/wZ2AB8O5C8ulEL9uP8mtymtmeZtZl9yh33wD8KOU/rVDPe1L9F2uNYymq13vQzBaa2fRi\n/WY2E/h+unu+u2uXPNkuZtac3oO75o9vy3t5MGgTEBGRXlTZ7vRO4DBizc57gCPz252amQMUN1qo\nsn30tcBi4ARig5Aj0z8PkS7q8R40s1OBbwNXEpvOrAJ2AV5IjPW8HniOu2vcu2zFzE4ETkx3dwSe\nR7yPrkjHVrj7R1LeBcCDwEPuvqBQT5/ey4NBwbGISA3MbB7wOWJ75xnETk4XAqe7++pC3qrBcUqb\nDnyW+CczB1gJ/BH4d3d/tD8fgwxv2/seNLN9gQ8DS4CdgMnEMIrbgZ8D/+vubf3/SGQ4MrPTiM+u\n7lQC4Z6C45Re83t5MCg4FhERERFJNOZYRERERCRRcCwiIiIikig4HoHM7DIz8zT5oq9lT01lL6tn\nvSIiIiLDwYjePtrMPkDsz32euy8b5OaIiIiIyBA3ooNj4APAfOAyYNmgtmT4WEvsYPPwYDdERERE\nZKCN9OBY+sjdLySWUxEREREZdTTmWEREREQkGbDg2Mx2MLN3mdlFZnaXma03s41mdoeZnWlmO1Up\nszRNAFvWQ71bTSAzs9PSAujz06FLUx7vYbLZrmb2v2b2gJm1mtlqM/u7mb3FzBq7OXdlgpqZTTaz\nM8zsfjPbnOr5nJmNzeU/zswuNrMV6bH/3cye1cvz1ud2FcpPM7Ov5co/ambnmNmcWp/PWplZg5m9\nwcz+YmZPm1mbmT1uZheY2WF9rU9ERERkoA3ksIqPEzvzAHQA64jtKheny+vN7Hh3v6UO59oALAdm\nEl8AVgP5XX9W5TOb2YuBXwDlQHYtsb/3s9LlZDM7sYe9vqcR28DuAWwEGoGFwGeAA4CXmtm7gLMB\nT+0bn+r+q5k9292vKlZah3bNAK4DdgU2E8/7zsBbgRPN7Bh3v7Obsn1iZpOAXwPHp0NO7Lw0BzgJ\neKWZvd/dz67H+URERET6w0AOq3gY+CSwHzDO3WcAY4CDgYuJQPanZrbVdqt95e5fdfcdgUfSoZe7\n+465y8vLedMe3+cTAejlwJ7uPhWYBLwd2EIEfN/o4ZTl7RSf5e4TgYlEANoBvMTMPgN8HfgyMMPd\npwALgH8ALcDXihXWqV2fSflfAkxMbVtKbOk4E/iFmTX3UL4vfpjacyOx3/r49DinA58GOoFvmNlR\ndTqfiIiISN0NWHDs7t909y+5+63u3pGOdbr7DcAJwB3A3sDRA9Wm5JNEb+z9wAvd/e7Uti3ufg7w\nvpTvzWa2qJs6JgAvdvcrU9k2d/8uETBC7B/+Y3f/pLuvSXkeAl5D9LAeYma79EO7JgOvcPffuXsp\nlb8ceAHRk743cHIvz0+vzOx44ERilYtnu/uf3b01nW+1u38B+Hfi/faJ7T2fiIiISH8ZEhPy3H0L\n8LLwYW8AACAASURBVJd0d8B6FlMv9SvS3a+5+6Yq2b4LPAYY8MpuqvqFu99X5fhfc7e/VExMAXK5\n3D790K4rygF74bx3A79Md7sr2xenpOvvuPvabvL8JF0fW8tYaREREZHBMKDBsZntaWZnm9ktZrbO\nzErlSXLA+1O2rSbm9aNnEOOeAS6tliH1uF6W7h7UTT23dnP8qXTdShYEFy1P19P6oV2XdXMcYqhG\nT2X74sh0/Wkze7LahRj7DDHWekYdzikiIiJSdwM2Ic/MXk0MMyiPcS0RE8y2pPsTiWEEEwaqTcS4\n27LHesj3aJX8eU90c7wzXS93d+8lT37sb73a1VPZclp3ZfuivPLF1Brzj6/DOUVERETqbkB6js1s\nJvAdIgC8gJiEN9bdp5UnyZFNStvuCXnbaGzvWQbFUG1XXvl99DJ3txouywazsSIiIiLdGahhFS8g\neobvAF7r7je4e3shz+wq5TrSdU8B4pQe0nrzdO52cUJc3twq+ftTvdrV0xCVclo9HlN5aEhPbRUR\nEREZ8gYqOC4HcbeUV03ISxPQnl2l3Jp0PcvMWrqp+5Aezls+V3e90Q/kznFstQxm1kAsfwaxTNlA\nqFe7junhHOW0ejymf6TrF9ShLhEREZFBM1DBcXkFg326Wcf4rcRGFUX3EGOSjVirt4u0hNkrisdz\n1qXrqmNh0zjgX6e77zezamNh30JsnOHEhhz9ro7tOsbMjiweNLPdyFapqMdjOi9dP8/Mnt9TRjOb\n1lO6iIiIyGAaqOD4r0QQtw/wTTObCpC2XP4o8C1gZbGQu7cBF6W7XzOzZ6YtihvM7LnE8m+bezjv\n7en6NfltnAu+SOxqtxPwezPbI7VtjJm9Ffhmyvc9d7+/xsdbD/Vo1zrg12b2wvKXkrRd9R+JDVhu\nB36+vQ119z8RwbwBF5rZR9M4c9I5p5vZiWb2W+DM7T2fiIiISH8ZkOA4rav79XT3PcBqM1tNbOt8\nBnAJ8O1uin+CCJznAVcQWxJvJHbVWwOc1sOpv5euXwWsNbNHzGyZmZ2fa9v9xGYcrcQwhbtS29YD\n5xBB5CXAB2p/xNuvTu36PLFV9e+BjWa2Hvg70Uv/NHBSlbHf2+qNwG+I8eFnAMvNbLWZrSNevwup\n0vsvIiIiMpQM5A55HwLeBtxEDJVoTLc/ALyIbPJdsdwDwGHAz4iArpFYwuwLxIYh66qVS2X/BryM\nWNN3MzEMYT6wYyHf/wH7EitqLCOWGtsEXJna/Dx339jnB72d6tCulcChxBeT5cRW1Y+n+g5w9zvq\n2NaN7v4y4MVEL/Ljqb3NxBrPPwfeBLy3XucUERERqTfrfvldEREREZHRZUhsHy0iIiIiMhQoOBYR\nERERSRQci4iIiIgkCo5FRERERBIFxyIiIiIiiYJjEREREZFEwbGIiIiISKLgWEREREQkUXAsIiIi\nIpI0DXYDRERGIjN7EJhMbP0uIiJ9twBY5+4LB/KkIzY4fmL5kw7Q2NhYOVa+XSqVANi8eXMlbc2a\nNQCsXbsWgPb2jqwyt7hKW22XywOYdU3LK5+vuTme5pYxLZW0CRPGAzBmzJjKsZaWlpS/uUvd+XO2\ntv5/9u48zu6qvv/463PXubNlDwRCSGRLkCIQqggqoVpEqUv96c+1CtpWa61rW9HaEruoXRRbWkXb\nWipi0dYfxSoW6hJAkKqBgJAQ1rAkISHbTDLrXc7vj3O+y9y5s4WZzMyd9/PxuI87+Z7v95zvHS4z\n537mcz6nH4Du7oNx28HuQwBUq1UAcrnkP2tLS8uQcdJ9ZjL+DwfPPXV1clBEJktnqVRauGbNmoXT\nfSMiIrPRli1bhszVjpSmnRyXSiUABgcH42PRN3hgYGDIv9PHogmtWZJxkrHo2PCJcHR+9Jxuiyaf\n0XO+kEzUo8lqNCFO91F/XXrs5P6GT5wrlcqwe4jGadRn+oODiEy6bWvWrFm4cePG6b4PEZFZae3a\ntdx1113bjvS4yjkWkRnJzJyZbZjA+evCNevrjm8ws+F/2hEREWlAk2ORJjHRyaSIiIgM17RpFVGK\nQfQMSYpFT08PMDStIk59CPm+kMrNtaHpDul0hCgtIkpzSI8XpTdEGRD5QvLtjsZJpzlE59c/p7+O\n+i+n0kWiY1HOcVp9LnSjVA2RJvFTYA2wZ7pvJHLf9i5WXvbd6b4NEZFpse0zF0/3LRyWpp0ci8jc\n4pzrBR6Y7vsQEZHZrenTKjKZTPzIZrNks1lyuRy5XI5isZh6tFAstlAqlYY9WlpahjzS10V91mo1\narUa5XJ52GNgYDA8BuLH4OAgg4ODQ85zzuGcw8zGjOpaJhM/6l9fPp+PH9FrjfquVCrxI7oXOTLM\n7BIz+5aZPWpmfWbWbWa3m9nbGpy7zcy2jdDP+pBCsS7Vb/QngvNDmxsh//b/mtmtZtYV7uEXZvYx\nMyvWDRPfg5m1m9kVZvZkuGaTmb02nJMzsz8ys4fMrN/MHjGz941w3xkze4+Z/czMDplZT/j6dyy9\nAnb4dceY2TVmtjuMv9HM3tLgvIY5x6Mxs5eb2Y1mtsfMBsL9/7WZzR9vHyIi0lwUORY5cr4I3A/c\nCuwEFgGvBK4xs1Occ398mP1uAj4JXA48DlydatsQfWFmnwI+hk87+DpwCHgF8Cng5WZ2oXNukKHy\nwP8AC4EbgALwZuBbZnYh8F7gBcD3gAHgDcCVZvaMc+4bdX1dA7wFeBL4J8ABvw58AXgR8NYGr20B\ncAdwAPgXYD7wf4FrzexY59xfj/ndGYGZXQ6sB/YB3wF2A6cDvw+80sxe6JzrHkc/I5WjWH249yYi\nItOnaSfHSb5vEoGN6v9GtX/T9YDraxhXK0kt42rN5/JGOb3p3N7o69HyfqM835obXnM5nb8c3Wv9\nc/rr6Pz0vUf5y436LJfLQFKqLvr3SPcqU+o059wj6QNmVsBPLC8zs6ucc9sn2qlzbhOwKUz2tjnn\n1tefY2YvxE+MnwSe75x7Ohz/GHA98Gv4SeGn6i49BrgLWOecGwjXXIOf4P878Eh4XQdC2+fwqQ2X\nAfHk2MzejJ8Y3w28xDl3KBz/BHAL8BYz+65z7ut1458exnmTc64WrvkMsBH4CzP7lnPu0Yl9x8DM\nLsBPjH8CvDK6/9B2CX4i/kngQxPtW0REZremT6sQmSnqJ8bh2CDwD/gPqi+dwuHfGZ7/PJoYh/Er\nwEeAGvCbI1z7wWhiHK65DXgMH9X9aHpiGSaqtwOnmVm6kHY0/mXRxDic3wN8NPyz0fjVMEYtdc1j\nwN/ho9q/MeIrHt37w/Nvpe8/9H81PhrfKJI9jHNubaMHyn8WEZmVmjZyLDLTmNkK/ETwpcAKoFR3\nyrFTOPxZ4fmH9Q3OuQfN7ClglZnNc851pZoPNJrUAzuAVfgIbr3t+J8tR4evo/FrpNI8Um7BT4LP\nbND2RJgM19uATyNpdM14vBAoA28wszc0aC8AS8xskXNu72GOISIis1DTTo4tE1ISaulSZtHXvq1a\nTdqi0mjlkB5RS6UcDL0KaqnyaNGxbC6Ue8umS8CFXenibaSTQFqUFjFaWsWQ1xOnVQzf6S5Kj4hK\n0zUq19Yo7SO9DbZMLTN7Dr7U2ALgNuBmoAs/KVwJvAMYtihuEs0LzztHaN+Jn7DPD/cV6Wp8OhWA\nuon0kDZ8ZDc9/r4GOc045ypmtgdY2qCvXSOMH0W/543QPpZF+J9/l49xXjugybGIyBzStJNjkRnm\nw/gJ2aXhz/axkI/7jrrza/joZSOHU0khmsQejc8Trres7rzJ1gUsNLO8c66cbjCzHLAYaLT47agR\n+js61e/h3k/GObfwMK8XEZEm1bSTY4vjvanocFiM1tvbC8BAf/I7Otksoz5ODJmMC88+ItuST+Ys\nhcLQzTwaRWMbLaKLvh5tE5BGC/KiilfptmjMKDrcqC2KGKc3BdEmIEfUieH5Ww3azm9wbD9weqPJ\nJHD2CGPUgOwIbXfjUxvWUTc5NrMTgeXAY/X5t5Pobnw6yUuAH9S1vQR/33c1uG6Fma10zm2rO74u\n1e/huBO42Mye65y7/zD7GNNpx85j4ywtgi8iMldpQZ7IkbEtPK9LHzSzl9N4IdpP8R9eL607/xLg\nvBHG2AscN0LbV8LzJ8xsSaq/LPA3+J8F/zzSzU+CaPxPm1lravxW4DPhn43GzwJ/ma6DbGar8Avq\nKsDXDvN+rgjP/2hmx9Q3mlmbmZ1zmH2LiMgs1rSRY5EZ5gv4ie6/m9l/4Be0nQZcBHwTeGPd+VeG\n879oZi/Fl2A7A7+Q7Dv40mv1fgC8ycz+Cx+FLQO3Oududc7dYWZ/BfwhcF+4hx58nePTgB8Dh10z\neCzOua+b2WvwNYrvN7P/xP+Z5rX4hX3fcM5d2+DSe/F1lDea2c0kdY7nA384wmLB8dzPD8zsMuDT\nwENmdiO+Akc7cDw+mv9j/H8fERGZQ5p2clyfohCOApAJ6QS5XPIX6EymLm0hFVOP2urrJENSY3jo\nOIS+hqYtNDonnYZRn/oQ9e3vYWg6RT6XtBWLfh3XYFhU2Kh+cXrh32jHZGo45+4NtXX/HLgY///e\nPcDr8BtcvLHu/M1m9jJ83eFX4aOkt+Enx6+j8eT4A/g3+Uvxm4tk8LV6bw19ftTM7gbeB7wdv2Du\nEeATwGcbLZabZG/GV6Z4J/DucGwL8Fn8BimN7MdP4P8K/2GhE9gM/E2DmsgT4pz7SzO7HR+FfhHw\nGnwu8nbgy/iNUkREZI6xRhO2ZrBn3zMOkjxcgP7+fgB6e/xzuZxMImfS5DiaCDeaHEebeRw62BO3\n7d27D4CDBw8O6af+63rR5PjiV16k5GORSWZmG88666yzNm4caQM9EREZzdq1a7nrrrvuCrXjj5im\njRxH0gveCgW/kC6aj+byycQx3l0unD+kxFpm6O50UT/158HQyfh4SqWlJ9D1EeP05Lh+ol2tJPfe\n1tY25PrxlmtT5FhERERkKC3IExEREREJmjZynI4YR9KRWIB0lkMURU1ye1PXh6BtNpMdcm76/Chq\nmy7XFh2rzxeGJKJbS3bFje8v0yB6Xa9QTPaLiCLHUf/pyHGUhhE9R+XsACqjpFyIiIiIzEWKHIuI\niIiIBJoci4iIiIgETZtWEaUkNNoFLjo22m5x6bSMKMUiWqyXG2WhXHpB3mBIZejv6xt2XXt7O9C4\nWkXUZ6O0iriUWz65LqqeEY0dVeVIv47R+hQRERERT5FjEREREZGgaSPHUcQ0HZmNoqdJVHh45DgX\nRVYtFWGtixz39w/ETfv3+xrDT+/aBcDjjz8et23fvh2APXv2AFCpJlHlC9atA+BlL3vZsHuONidp\nVII6ClTXakkUulb0J0aR43Q0O1ogGB3rC1FsrzlrXIuIiIgcLkWORURERESCpo0cx3nC2dywY5mM\njyZnbPhng6jkWX85ibDuP3gIgG1P+KjwIw89HLc9smUrAA8/6o/t6zoQt3UsnA/A0cceA8DgQNLn\nF/75SwDs7doXH/s/r3ktAH3dfrxSa2vcls9HryPKOU7uvVbzkeaWWjG8viRyHOdeZ0KU2JLybc26\nO6KIiIjI4VLkWEREREQk0ORYRERERCRo2rSKTGb4orZ4NzvzL/tAV3fc9uBDDwFwsKcHgKpL0g8e\nCikTT4YFdvfetSluezSkVbSUfEpDoa0Ut73g/BcBsOqkEwHI55NFfg898AAA37rhP+NjLiweXNA5\nD4BTV6+J21Y95zlA45JshQJD2tI7ARbDIr3Wqj+po6Mtbkvv5iciIiIiihyLyCxhZhvMbEKJ8mbm\nzGzDFN2SiIg0oaYNHTaKsEaR4+27fGm1b3/ve3Hb5gd9BLgYFsG1tbbEbeV+v5Bu6VFHAbAsLLAD\neGjzFgAGBv1CvoFaOW7rPeSj0M887cu8kaoO197eAUAuX4iPXf21rwFw8YUXAbB69alxWy1aT2fR\n5ibJHCEq/ZYsPhw+f4gW36X3LElHmEVERESkiSfHIiLAGqB3um9CRERmD02ORaRpOecemO57EBGR\n2aVpJ8fx4rvUirzo6+/+t0+nuPWOn8Rti49aCsC+br9Ir1JN0iPmhUV2+/bvB+CRRx6J23Kh/vBA\nSL0Y7E12wfvf0P+KVccD0NbREbflcz6l4Zhjjo2PnXLyKQAcHY51hfrKkCwGXLRose+rlCyss5Bz\n4ULOhFmyK2CSYjH8+yEyU5jZq4EPAKcCC4G9wEPAN5xzX6g7Nwf8IXApsALYDXwd+GPn3GDduQ64\nxTm3LnVsPXA5cAFwPPBBYDVwEPgO8HHn3NOT/iJFRGRW0II8EZlWZvbbwA34ifF/AZ8FbgRK+Alw\nva8DvwfcBnwR6MNPlr80waE/BFwF3AN8HtgaxrvDzJZM+IWIiEhTmFOR466uLgC2hsV3J550Qtx2\n4on+6507fcCo92BS5m33Dn/s/i2bAdj8i/vitgVt7QAsXLQIgKOWHR23HX+8jxivWeNLsi1fflzc\nFp3f0pIs/CuEmmy1so8+Hwpl5QAO9fq0yb37fPR6yaLkd/dRS3zUO5cNq+2GLOiPosip1YCBpVfn\niUyfdwODwPOcc7vTDWa2uMH5JwDPdc7tC+f8EX6C+3Yz+9gEor6vAF7gnLs7Nd4V+EjyZ4B3jacT\nM9s4QtPqcd6HiIjMIIoci8hMUAHK9Qedc3sanPvRaGIczukBrsX/PDt7AmNek54YB+uBLuAtZlac\nQF8iItIkmjZyXKvVhh3bu3cvANm8/0xwyslJ5PjoxT4SuyREgh/aujVu21PxG4L0hRzg8194Xtx2\nyoknAbDqFN/XiuNXxG1LQn5wqcXnLOeySem0aJOSai3ZbKQcNuyoZPx/llo+eQ3Vqj/vUF8/ADt/\ncX/ctvoEX0buhJNWAeBSG5gQBYejUnAoWiwzzrX4VIrNZnYdcAtwu3PumRHO/3mDY0+G5wUTGPeW\n+gPOuS4z2wScj690sWnYVcOvWdvoeIgonzWB+xERkRlAkWMRmVbOuc8B7wAeB94PXA/sMrMfmdmw\nSLBz7kCDbqKVsMPzh0a2a4TjUVrGvAn0JSIiTUKTYxGZds65rzrnzgEWARcD/wy8BLhpChfHHTXC\n8WjhQNcUjSsiIjNY06ZVRAvxqqn0ij2hFFu0gM1SKQ17d/kgklX9+UvCgjmAhQvPAeD0008H4Lhj\nlsdtS8N5hXa/sC6XS76l2ZDCYJnoM0iS0hClSeBS6R81H/wqhF39WsJufQCV8Dr6+n0Kxa6eZM3R\n1oceBmDVCX4BYHqdnYV8Cheea6nxKgM+xbNUTMrCiUynEBW+EbjRzDLAO/GT5G9NwXDnA19NHzCz\necAZQD+wZQrGFBGRGU6RYxGZVmZ2gTUunbI0PE/VDne/YWZn1h1bj0+n+Dfn3MAUjSsiIjNY00aO\nCwW/+G333nhRO7ue8QvfT3rOiQBkMqnfx2HBWl+f38zj6KXJX1xLLUOjwsVisog9Kr8WRYLTC96y\n4fyomlwt9fs/G6LD+dTHk/07/PqjfNYfPHQgKcm27fEn/NglH03euTOpeHX8Ch8xLpd9JDifrPuj\nGhYTRgv/BgeTPRL6+/3ivtJRihzLtLoeOGRmdwLb8H9ieTHwy8BG4PtTNO73gNvN7JvATuBF4bEN\nuGyKxhQRkRlOkWMRmW6XAT/DV3Z4L34jjjzwUeAC59ywEm+T5Iow3hkku+RdDZxbX29ZRETmjqaN\nHEc5tlH5NoCjly0DktJq2czwv+RGkeN0BLjrgF8cH0WHBwb647Zy2R+rhCBvb1/yF+DWEOVdvMSX\ndIui2QB9Pb4s3O5dO+Nj927yJVe3PuA3G3n0kW1xWxT1fvVrXwfAa3/9/8RtC+bP92OHjUJKpeQ/\nazUqD1f1N9jfn/yluD9seS0ynZxzV+F3qhvrvHWjtF2Nn9jWHx+1duFI14mIyNylyLGIiIiISKDJ\nsYiIiIhI0LRpFXGptJSWsLAuSj+oVStxW7RALimxllwXLXRrb/e75+3cmaRCdIdd8wi73/X2JSkX\nDz74IAAnnuh3z1u6KNm86/s3/7c/Z2tSLapr/75wf77PSjkpuzYYFtZlQlm4fGrV3Z133gnAOc/3\nG3UtP/bouK1c9gvwwuVDFuQNDiavX0REREQUORaROcY5t945Z865DdN9LyIiMvM0beS4t8dHhx96\n+KH4WK7gS7AN9odoamX4Ivio3GqlnLTdesutAJx22mkArF69Om6LAsxPPe3LsKU3AWkp+jJve/f4\nxXS93cmut/ds2gTAoe5kE65M6C2X9X0U8klfuYqPIpdKfjHhli33x23/dt21ACxd4iPTnR3tcVu0\n6K4Srk8vyBsYUBlXERERkTRFjkVEREREAk2ORURERESCpk2reHrX0wB8+9vfjo+d/fxzAOgIC+tc\nLVnwFqVTFEIqxJ49SX3krVu3+rawG96KFSvitiiNYuWKYwGolJNFbm0thah335ZKYzju2OUAPNzb\nk9yD8/dTrYVkjUz6s4tfUZcLCwfnz58Xt6xceVwY26eC7E3tClge9MfKleE75FUqWpAnIiIikqbI\nsYiIiIhI0LSR4/5+X1Itm01e4jPP+B1hO9o7gKHl3pzz0dqoVFo5tSDvxBNPBKC11S+G6+pKFtYt\nX+4jwPPmdQJw4EDSVir6cmv5EF12qepya9asAWDrls3xsUoou5bJ+UhzsZDcezHstlcK97Bq1aq4\n7fWvfwMAPaGsXNeB7ritGqLjtRCNjl4nDKlWJyIiIiIociwiIiIiEmvayHEu78u2nfic58THdj/j\ny63Nf56PHEebgkCyMUg15OaWWopx24oVPjocRaN3794Vt51wgt/g46c/+ykAP/rRhrjtXe96JwDH\nrzgegB1P7ojbjg05x4uXHhUfGwj9t3f6+yuk7q+trQ2ArWFjka6DB+O2XU/7+zkq9PXcU58bt/WE\n1xXSmaml8qzbWlsRERERkYQixyIiIiIigSbHIiIiIiJB06ZVRIvtFixYEB97+OGHAdi+fTsAi5Ys\nidssPEeL1CxVRm3+/PkAdHf7hW5PPfVU3JbJhBJweV+27ZEwBsDWrQ8OaTuQWsiXDSXZTjrp5PjY\n/v37w9hRWbkktePRRx8F4LawW182m4/b2sICw5dfeCEAmzdviduiVI2oPFx6geKS1OsXmUvMbCXw\nGPCvzrlLpvVmRERkRlHkWESmhJmtNDNnZldP972IiIiMV9NGjqPSZYVCEn3NZHy09sBBHwEutiUL\n0vr6+sI5/vNCb39f0lco67Zw4UIAduxIFtbt3+ejvauO96XVXnXxq+K2XBjvmd1+IeCBcC7Apk2b\nAHjggQfiYz09fkOQfM5HhTs7OuO23oO+baDXbyRSakk+1yxduBiAfbv9xiXP7Nwdt7kQC8+G70NH\nZ9KnmT4biYiIiKRpdiQiIiIiEjRt5DiKEifZxJALEdl777kXgLPySd5uR8fQ8m75XDZue/TBh4Ak\nTzjaMhrgkUceAeC45X4L56hsG8DOnTsBuOeuewDYnNrw48FQki3KY073mw/5xBmSe4i2rl6yyOcJ\nt6eiytT8a3zyiSf99anX1drmt8ouhr4O9fTGbdWqtgGRqWFm64HLwz/fYWbvSDVfCmwDfgR8Ergx\nnPtCYAGwyjm3zcwccItzbl2D/q8G3hGdW9f2fOAjwIuAxcA+4BfAPznnvjnGfWeAK4D3A9cDb3XO\n9Y12jYiINJemnRyLyLTaAMwHPgDcA/xnqm1TaAM/If4Y8GPgK/jJ7ODhDmpmvwV8EagC3wYeApYC\nZwPvBUacHJtZC3At8DrgH4D3O+dqI50vIiLNSZNjEZl0zrkNZrYNPzne5Jxbn243s3XhywuB9zjn\nvvRsxzSzU4EvAN3Ai51z99e1Lx/l2oX4yfS5wGXOub+cwLgbR2haPd4+RERk5mjayfHjj/sUg76+\n/vhYd/chAH70/R8CsO2RR+O2Vav8grpoB7lyOQletYSSavPmzQOSdAmA/73zfwHoaPVpGU8/neye\nt3evXyB3MOxmV61V4rZMSNEolUrxsTitIufHay21xW2l1lI45p/z+WShYbTosFRqGdZnsdgSdT5k\nDN+XdsiTabdpMibGwe/gf6b9Wf3EGMA599TwS8DMjgf+GzgB+A3n3LWTdD8iIjILNe3kWERmhZ9O\nYl/nhOfvTeCaU4CfAG3AK5xzP5jooM65tY2Oh4jyWRPtT0REplfTTo53bPfl1vbu3T/sWGXQl2Z7\nZufTcVtviCr39fkFa719ycK1JUctBaBznl8E91Bqo48HH/AL63LhW5kujxZFaed1+ohzsZREe4tF\nv8AuWgAIScS3UGwNz0lbS0spPBfD9UlbFEWOxosWDgJkwv1ECxTzYUOS+rFFpsnTY58yblEe8/YJ\nXHMysBCfB33XJN6LiIjMUirlJiLTabSSKY6RP8DPb3As2oLy2AmM/1/Ax4EzgB+Y2aIJXCsiIk1I\nk2MRmSrV8Jwd9ayR7QeOqz9oZln8ZLbeneH5FRMZxDn3aeBDwJnABjM7aoL3KSIiTaRp0yq6QppE\nd3dPfKyjcwEApz/PpwEW8qmX73wAy1X9grxKNVk8N1jxX9+zya/x6elOyp4es8z/7i6FVIhiMZU6\nEdIWonSKKCXCf+3bWhqcXyiE5yGpE752sVlSt7nu1uO29KK7bEinyMTPyfXRboAiU2Q/Pvq74jCv\n/ylwkZld6Jy7OXX8E8DxDc7/IvAe4I/N7Cbn3OZ0o5ktH2lRnnPu82bWj692cYuZ/Ypzbkejc0VE\npLk17eRYRKaXc+6Qmf0v8GIzuxZ4kKT+8Hj8DfBy4AYz+wZ+M49zgVX4Osrr6sbbbGbvBa4C7jaz\nG/B1jhcBv4wv8XbBKPd7VZgg/zNwa5ggPzHOe21k5ZYtW1i7tuF6PRERGcOWLVsAVh7pcc057ZIm\nIlPDzE7E7zh3Ln73O6Nuh7z6Gsh1178a+BPgNKAH+B/go/id9UbaIe+FwO8DL8bnJu8B7sXv6+/U\nnAAAIABJREFUkPcf4ZyVwGPAvzrnLqm7/s3AV/EL+37FOfcoh8HMBvApJfcczvUikyCqtf3AtN6F\nzHXP5n24Euh2zq2avNsZmybHIiJTINocZKRSbyJTTe9BmQlm4/tQSaciIiIiIoEmxyIiIiIigSbH\nIiIiIiKBJsciIiIiIoEmxyIiIiIigapViIiIiIgEihyLiIiIiASaHIuIiIiIBJoci4iIiIgEmhyL\niIiIiASaHIuIiIiIBJoci4iIiIgEmhyLiIiIiASaHIuIiIiIBJoci4iMg5ktN7OvmNkOMxsws21m\n9nkzWzDBfhaG67aFfnaEfpdP1b1L85iM96GZbTAzN8qjZSpfg8xeZvZ6M7vSzG4zs+7wfvnaYfY1\nKT9Tp0Juum9ARGSmM7MTgDuApcANwAPA84EPABeZ2XnOub3j6GdR6Odk4IfAdcBq4FLgYjN7oXPu\n0al5FTLbTdb7MOWTIxyvPKsblWb2CeB5wCHgKfzPrwmbgvfypNLkWERkbF/A/xB/v3PuyuigmX0O\n+BDwF8B7xtHPp/AT48855z6S6uf9wN+GcS6axPuW5jJZ70MAnHPrJ/sGpel9CD8pfhg4H/jRYfYz\nqe/lyWbOuekaW0RkxgsRjoeBbcAJzrlaqq0D2AkYsNQ51zNKP+3AbqAGLHPOHUy1ZYBHgePDGIoe\nyxCT9T4M528AznfO2ZTdsDQ9M1uHnxxf65x72wSum7T38lRRzrGIyOguCM83p3+IA4QJ7u1AK3DO\nGP2cA5SA29MT49BPDbipbjyRtMl6H8bM7I1mdpmZfdjMXmFmxcm7XZERTfp7ebJpciwiMrpTwvOD\nI7Q/FJ5PPkL9yNw0Fe+f64BPA58FbgSeMLPXH97tiYzbjP9ZqMmxiMjo5oXnrhHao+Pzj1A/MjdN\n5vvnBuBVwHL8XzNW4yfJ84FvmJny3mUqzfifhVqQJyIiMoc4566oO7QV+LiZ7QCuxE+U//uI35jI\nDKHIsYjI6KIoxrwR2qPjB45QPzI3HYn3zz/hy7idERZGiUyFGf+zUJNjEZHRbQ3PI+W/nRSeR8qf\nm+x+ZG6a8vePc64fiBaLth1uPyJjmPE/CzU5FhEZXVTH88JQci0WomvnAb3AnWP0cyfQB5xXH5UL\n/V5YN55I2mS9D0dkZqcAC/AT5D2H24/IGKb8vfxsaXIsIjIK59wjwM3ASuB365o/iY+wXZOux2lm\nq81syM5RzrlDwDXh/PV1/bwv9H+TahxLI5P1PjSzVWa2sL5/M1sC/Ev453XOOe2SJ8+KmeXDe/CE\n9PHDeS8fadoERERkDA22Ot0CvABfr/NB4Nz0Vqdm5gDqN1losH30T4E1wGvwG4ScG35xiAwzGe9D\nM7sEuAr4MX7jmX3ACuCV+FzPnwO/6pxT7rsMY2avBV4b/nk08HL8++i2cGyPc+73w7krgceAx51z\nK+v6mdB7+UjT5FhEZBzM7DjgT/HbOy/C7+J0PfBJ59z+unMbTo5D20LgcvwvmGXAXuB7wJ84556a\nytcgs9+zfR+a2S8BHwHWAscAnfg0ivuBbwJfcs4NTv0rkdnIzNbjf36NJJ4IjzY5Du3jfi8faZoc\ni4iIiIgEyjkWEREREQk0ORYRERERCTQ5FhEREREJ5tTk2MxceKychrHXhbG3HemxRURERGR85tTk\nWERERERkNLnpvoEjLNqysDytdyEiIiIiM9Kcmhw751aPfZaIiIiIzFVKqxARERERCWbl5NjMFpvZ\ne83sBjN7wMwOmlmPmW02s8+Z2TEjXNdwQZ6ZrQ/HrzazjJm9z8x+amYHwvEzwnlXh3+vN7MWM/tk\nGL/PzHab2b+Z2cmH8Xo6zOwSM/ummd0Xxu0zs4fN7MtmdtIo18avycxWmNk/mtlTZjZgZo+Z2d+Y\nWecY459mZl8J5/eH8W83s/eYWX6ir0dERERktpqtaRWX4be/BKgA3fg94deEx9vM7GXOuXsn2K8B\n/w94DVDFb6nZSBH4EXAOMAj0A0uANwGvNrNXOOduncC47wCuDF9XgS78B5cTwuMtZvZa59z3R+nj\necBXgIXhvjPASvz36XwzO9c5NyzX2szeB/wtyQelQ0A7cG54vNHMLnbO9U7g9YiIiIjMSrMycgw8\nAXwcOB0oOecW4SesZwM34SeqXzczG7mLhl6H3+P7vUCnc24BcBTwaN15vxPGfjvQ7pybB5wJ3AW0\nAt80swUTGHcP8BfA84HW8Hpa8BP9a4G28HraRunjamAT8EvOuU78BPddwAD++/Jb9ReY2Wvxk/Ie\n4A+BJc65jvAaLgIeAtYBV0zgtYiIiIjMWuacm+57mFRmVsRPUk8F1jnnbkm1RS92lXNuW+r4euDy\n8M93O+e+PELfV+OjvABvc85dW9e+GHgAWAT8sXPuz1Nt6/DR5sedcysn8HoMuBl4GXCJc+5f69qj\n13Q/sNY5N1DXfiXwPuBHzrlfSR3PAo8AxwMXOeduajD2CcC9QAFY4ZzbOd77FhEREZmNZmvkeERh\ncvg/4Z/nTfDyvfjUhLE8Dny9wdh7gC+Ff75+gmM35Pynl++Gf472ej5XPzEO/jM8n1Z3fB1+Ynxf\no4lxGPsR4E58+s26cd6yiIiIyKw1W3OOMbPV+IjoS/C5te34nOG0hgvzRvFz51xlHOfd4kYOud+C\nT/k4zcwKzrnB8QxsZsuB38NHiE8AOhj+4WW01/OzEY5vD8/1aR7nhueTzOzpUfqdF56PG+UcERER\nkaYwKyfHZvYm4KtAVEmhhl/EFkVO2/F5uqPl6DbyzDjP2z6Otix+QrprrM7M7HzgO/j7jnThF/oB\nlIBORn89Iy0ejPqo/2+9LDwX8XnVY2kdxzkiIiIis9qsS6swsyXAP+Inxt/ALzZrcc4tcM4d7Zw7\nmmQB2UQX5FUn707HJ5RK+xp+Yvx9fCS85Jybn3o9H45On8Sho//2NzjnbByP9ZM4toiIiMiMNBsj\nx6/ATyQ3A29xztUanDOeSOizMVp6Q9RWBfaPo68XAsuBfcBrRiiZNhWvJ4por5iCvkVERERmpVkX\nOcZPJAHubTQxDtUdfqX++CQ7fxxt940z3zh6PQ+OUkv4ZeO+s/H7SXg+3cyOnYL+RURERGad2Tg5\n7grPp41Qx/i38AvaptJKM3tz/UEzWwj8dvjnv4+zr+j1nGRmLQ36vBC44LDucnQ/AJ7E50b/9Wgn\nTrBms4iIiMisNRsnx98HHL402d+Z2XwAM+s0sz8A/gFfkm0qdQH/aGZvNbNcGP90kg1IdgNfGGdf\ntwO9+NrIXzWzZaG/kpm9E/gWU/B6wm5578N/L99sZv8ZbZMdxs+b2dlm9lfAY5M9voiIiMhMNOsm\nx865rcDnwz/fB+w3s/34/N6/wkdEr5ri2/gicB9+Id0hM+sC7sEvDuwF3uCcG0++Mc65A8DHwj/f\nAOwwswP4LbH/GXgY+OTk3n489rfxu+gN4rfMvtvMes1sL9CHLw/3ByTl3ERERESa2qybHAM45z6M\nT1+4G1++LRu+/iBwMTCeWsXPxgB+U4w/xW8IUsCXgbsOOMs5d+tEOnPO/R1+6+ooipzD77R3Ob4e\n8Uhl2p4159y/AKfgP3Dcj19I2ImPVm8I93DKVI0vIiIiMpM03fbRUym1ffQnVdpMREREpPnMysix\niIiIiMhU0ORYRERERCTQ5FhEREREJNDkWEREREQk0II8EREREZFAkWMRERERkUCTYxERERGRQJNj\nEREREZFAk2MRERERkSA33TcgItKMzOwx/Fbs26b5VkREZquVQLdzbtWRHLRpJ8eX/t5fOQCXTapx\n5EsFAHIF/7ILhWLc1lL0X+cL/px8Phu3ZawKQGs4vy1XSK7L5v0XBX9+LWNxW7Xqr6vVagAkLZDP\nDf/WDwz0+/PMB/T7+weS8/P5Ief29/fHXw+G/gcqFQD6+vqG9d3X1x+uq8XHnPPjfPlTv2vDLhCR\nZ6uzVCotXLNmzcLpvhERkdloy5YtDec0U61pJ8cicnjMbANwvnNuSj80mdlK4DHgX51zl0zlWNNk\n25o1axZu3Lhxuu9DRGRWWrt2LXfddde2Iz1u006Oiy0+0prJJ7/fCyG6WwhR4lwqcjww4KO0LQV/\nXWtLS9JW8Z9aLOevr1gSja6EAHMILpPLJN/SXIgwV0JEt1xOIsEW7iuTSdK+W1vbhpyfjjVH9aij\naHQ2m0S228PrKZR9Wy5Vujqb8ee1Ff3r6eo5lNx7VQFjERERkbSmnRyLyGF7O9A63TfRDO7b3sXK\ny7473bchIjIttn3m4um+hcOiybGIDOGce2K670FERGS6NG0pt0LBKBSMYi55LOxsY2FnG+0tBdpb\nClQH+uNHSy5DSy5DR0uRjpYig7098YNqDao1zMAMsoV8/CCXhVyWSqVMpVLGlSvxw2rV8KhhtRoZ\niB/VanXYo1arUavVcM7hnCOTycSP6Fj0yOVy8aNarVGt1jB8IkaxUIwf8fcjn6eQz9PWXoof+UKG\nfKFp3wKSYmaXmNm3zOxRM+szs24zu93M3tbg3A1m5uqOrTMzZ2brzez5ZvZdM9sXjq0M52wLj3lm\n9vdmtt3M+s1ss5m938zGlcdjZieb2WfM7Odm9oyZDZjZ42b2ZTNb3uD89L2dEe7tgJn1mtktZnbu\nCOPkzOy9ZnZn+H70mtndZvY+i1bFiojInKNfACJzwxeB44Fbgc8D14V/X2NmfzaBfl4I3Aa0AF8B\n/hUYTLUXgO8DLw9j/CMwH/hb4O/HOcbrgPcATwL/BlwJbAZ+E/iZmR07wnVnA3eEe/sn4DvAi4Af\nmNkp6RPNLB/a/yHc39eBL+N/Jl4ZXpeIiMxBTZtW0dfnF54tWTQ/PtZa9C+3XPblzNpbkshqZ2cn\nkJRMa0u1VWp+oVsGv7itmCrlVq36xXNmoUSaleO2XNZ/9jBCEC5V5i0Kyw0OJvOKaJFd9FyppPoK\npd+itsGBZHFf/2D4OizuK8cL+pKFhvG/K8l4lXINmTNOc849kj5gZgXge8BlZnaVc277OPq5EHiP\nc+5LI7QvAx4N4w2EcS4Hfga818y+4Zy7dYwxrgGuiK5P3e+F4X4/AfxOg+suBi51zl2duubdwFXA\nB4D3ps79I/wE/u+BDzrnquH8LH6S/E4z+w/n3A1j3CtmNlI5itVjXSsiIjOPIscic0D9xDgcG8RH\nTnPAS8fZ1aZRJsaRj6Unts65fUAUnb50HPe6vX5iHI7fDNyPn9Q2cnt6Yhx8BagAz48OhJSJ3wOe\nBj4UTYzDGFXgI/jPr28d615FRKT5NG3kuLXVR35LxWTzjFLY/KMUSrpVaslnAxeirS6UT2ttb4vb\nonJr2RC9TcdbM6FUWnffPgAefuKxuO2MM88EIBdtKJIaLxo7U0tvyuHjyVGUuFKNf2dTyA8tC1dN\nXdfa3gFAf8Wfn88l12WL/rr+3l4/xmASva5Uh6SVShMzsxXAR/GT4BVAqe6UkVIV6v10jPYKPrWh\n3obwfOZYA4Tc5LcClwDPAxYA2dQpgw0uA/h5/QHnXNnMdoU+IicDC4GHgE+MkArdB6wZ617DGGsb\nHQ8R5bPG04eIiMwcTTs5FhHPzJ6Dn9QuwOcL3wx0AVX81pzvAIojXV/n6THa96QjsQ2umzeOMT4H\nfBDYCdwEbMdPVsFPmI8f4boDIxyvMHRyvSg8nwRcPsp9tI/jXkVEpMlocizS/D6MnxBeWp92YGZv\nxk+Ox2usPzcsNrNsgwny0eG5a7SLzWwp8H7gPuBc59zBBvf7bEX3cL1z7nWT0J+IiDSRpp0cL+7w\nC+yK2SSVoZDzfz4tV31KwmA5+eushXSKYktYbJf63Z4LXUTVrSybfNsyGX/+wYN+AeAT25K0iued\nfrofJ+zCO1BJ/nxbDKkd+Qa74IUnLLULXjks3IsKbJVak7+KW84HuMqVfgB6evfHbR1F39bR4V9E\ndzaZ2+w5pAV5c8SJ4flbDdrOn+SxcsC5+Ah12rrwfPcY1z8Hvxbi5gYT4+Wh/dl6AB9lPsfM8s65\n8lgXHK7Tjp3HxllaBF9EZK7SgjyR5rctPK9LHzSzl+PLo022T5tZnKZhZgvxFSYA/mWMa7eF5xeF\nyhFRH+34snDP+gO9c66CL9e2DPg7M6vPv8bMlpnZqc92LBERmX2aNnLc2+tTFGsuSaV0Xf5YW1jA\nVmxJXn4UtY3KoMWL6IBMLSyUC5HcciriXAlR4T37fLT2UG9f0haVVCu2hI6SKHG14qO26bVA0cKg\ng4d8FLqQKidXCn24EPUup/ZoqNX2h3P8Av/+SvKZp6fsz7tr4yYAnnj43rjt7HUXIHPCF/BVIv7d\nzP4D2AGcBlwEfBN44ySOtROfv3yfmX0byAOvx09EvzBWGTfn3NNmdh3wJmCTmd2Mz1P+VaAf2ASc\nMQn3+Wf4xX7vAV5lZj/E5zYvxecin4cv97Z5EsYSEZFZRJFjkSbnnLsXuABfReJifI3gTvxmG1dN\n8nCDwMvwi/7eBLwbn+P7AeB94+zjXcCn8BU1fhdfuu07+HSNUXOWxyukUrwWeDuwFfg1fAm3i/A/\nF/8YuHYyxhIRkdmlaSPHlVAObU9Xb3Kwy0d8l2X8X1Hb2pLIbDFEacth442+gSQNMRtKuRWiSHMt\naauG85/e/QwAltogpKfP5wC35HzUN8pPBqiFqHI2lVccRY4LBV9+Lopmp0XR60ot2eiDEL1uyfvy\nc0vnJVWrNt9/DwA//O53/RguiXqve/mvDetfmpNz7g7gV0Zotrpz1zW4fkP9eaOM1YWf1P7uGOdt\na9Snc64XH7X9owaXTfjenHMrRzju8BuOXDPafYqIyNyiyLGIiIiISKDJsYiIiIhI0LRpFR3zfWpB\nNp/sQutq/uUeONgDQJUkPWJRSKuohb/OZtLl2vJD29KpEIWwU91TO/weB0sWzo/bii2tAOSyPk1i\nsJqUTot2wcukVuRFO/EVMz4No1xLyslVw255fufb5HqASs3vaVCr+vvq2bU9blue/V8A3v7yhQA8\n3nNy3LZ48VGIiIiISKJpJ8cicmSNlNsrIiIymzTt5PhQty+HViknC9eKLX4hXjGURbNMEgHu6/dR\n5Kj8WhSphWRTjvZWH/nNpZb+DPT6KPQze305tUVLlsZtUaQ5Cg5XK8m95Ap+cV46AjzQ3x+uC+Om\nxslkokizjxwPpvqyaPHhrscB2Hjbd+K2N71qJwBLfRCbfPdJcdv+7iF7LIiIiIjMeco5FhEREREJ\nmjZyTNlHfjvbWuJD+VBJrVKLosTJ6VHRtDinN7UJSCVsAuIYWmoN4OkdTwEwMOBLpGXzSXm4vhAJ\nzhf8sXRptigonI5s12puSGMtdX427/9T1UJEu1JJ5SOHbaNv/q8fALD1F0nO8YoT/OvIDMwDYNnq\n4+K2XT09iIiIiEhCkWMRERERkUCTYxERERGRoGnTKoohhSKXmv4XCj5foSMsyMuQ7FhXDakWxVKU\nFpGshiuHrwfLPnWirZB823Y8tQOAQ3v9Dnm7n3w8bquc+UsAZMNnkEImKeVWzGVDn0k5ucpgSMMI\n+R/5TJK+MTDg0y9c6KtY7Ijbbvr+jwG447at/tz+pHzdF7+8G4DXveFNAMzPJn261NciIiIiosix\niIiIiEisaSPHvT29ANSqqUVtUfk0fFshl0RyS2GRXSHrj/UNJNHXQ6HkWX9vHwAHi8miu1wovHbe\nWh8lXnp0srFGKefH7mjxUWKzJFKbz/uvXUvyn2Cw6M+LNhmpVpJ7L4fXcTC8rp/+/M647Wd33ALA\n/E7/b9eRXLd40SoATl3tN//o6++N29pbktchIiIiIooci4iIiIjEmjZyjPPz/t5Dh+JDrSVfzmzN\nKX4jjMXz58VtxShJuS6/GGAg9TVAIZfkKhei+nAWbTudfN6IosPFEGnOpDYdibaKTstmhx5zqe2j\no/4P9fq85GOiXT2AXz33LH9KzZ+TKyT9dHa2+3to9znKP960OW4rV1O17EREREREkWMRmTnMbKWZ\nOTO7epznXxLOv2QS72Fd6HP9ZPUpIiKzhybHIiIiIiJB06ZV5HL+pRVakvl/b/cBAE495UQAVhy/\nPG6rhIVqUbpDJpf61lRDWkWUFpGdooVsbugOefG4QCVs57fsqAUAnHziiuHX1/ziwO4DXfGhwYo/\ntmPXXgAWhTQLgD37D0zKbYtMo+uBO4Gd030jIiLSHJp2ciwizc851wV0jXmiiIjIODXt5DgXqqa9\n8qJ18bHHHnoQgBuu/38AvOxXk7ZTTjkFSErAlctJKbe9u58CwIVFfh3zl8RttZo/Zlkf7i0UknJt\nlbDgzbmktFp8XdVHdC1jw9qiCPJgX1J2Lbqv5cf70myVWtLnQK+/153b/YYkD257LG470NMDwP5u\n/9xWWhy3dXR0Dh9bZIYws9XAZ4CXAEXgbuBPnXM3p865BPgX4FLn3NWp49vCl6cD64HXAccCf+Gc\nWx/OOQr4FPBrQCewFbgCSHbyERGROadpJ8ciMqutAn4C/AL4ErAMeCPwPTN7i3PuG+PoowD8EFgI\n3Ax0A48BmNli4A7gOcCPw2MZcFU4d9zMbOMITasn0o+IiMwMTTs5njff59YetzzZlGPNCT7HeNu2\nJwAoltritmiTjYGKL592IJW365yP8pZD/u6BA0mubjZfAqAQNtSwbFKubWDAbw1drYaSbA2CxOmS\nblGAuTzorxvo6Yvb+vv9sQe2PurvIWxMAlCp+D56en2Ocvdg0uehENnuC1Hv3U88Fbe1dial7ERm\nmJcAf+Oc+4PogJn9PX7CfJWZfc851z1GH8uAzcD5zrmeurZP4SfGn3fOfajBGCIiMkepWoWIzERd\nwJ+mDzjnfg5cC8wHfn2c/XykfmJsfqvKtwIH8SkXjcYYN+fc2kYP4IGJ9CMiIjODJsciMhPd5Zw7\n2OD4hvB85jj66AfubXB8NdAKbAoL+kYaQ0RE5qCmTat4eNtuAL51/Q/iY6esWgbA/E6/u1z6r7JP\nPO4Xsw2WfepESykp19ZS9Avrsvjd8PKVZGc517vHn5NfCEB/V7Ij3+5d/h56B/2CuSj1AqC1tS2M\nk5RW23vAzwW6D/lAV39/f9w2OODH7B+Mxk5/rgn3VfCvK1fsiFtK2UI45lMoWkvJrns9fUnahsgM\ns2uE40+H5/HkBO12jVbDJteONYaIiMxBihyLyEx01AjHjw7P4ynf1mhinL52rDFERGQOatrIcVjT\nxn1bnoyP7dvnfyd2tvqXnbFkhVyp3UdwB0JktrsvlaZY8Ivsli70v0uXH5X8Ti1k/CK4/tozYeCk\nBNzgIV9+LR+u7+1JRZWf8feSaUmivI/v9Bt1HOzzfSye3xq3FfO+RFy26I+F/T4AsPCfsRwW/g2m\nItuEhXjRIj/yyYLBzqIW5MmMdZaZdTRIrVgXnu9+Fn0/APQCZ5jZvAapFeuGXyIiInOFIsciMhPN\nA/4kfcDMzsYvpOvC74x3WJxzZfyiuw7qFuSlxhARkTmqaSPHIjKr3Qr8ppm9ALidpM5xBnj3OMq4\njeXjwEuBD4YJcVTn+I3AjcCrn2X/IiIySzXt5Li14F/a4GBqAVo1pFGU/SK1/p5kwVtrxadHZPL+\nnIFssniuv+r76n7a/z7esSfZuW7hPF/nuL3V5znMLyTB+NYw3ME9fmFeNRWoPzTo+9zbszcZJ+P7\nGqj5tmJ/cu99YUGe4dMjcrlC3NZW8ikXlZo/v5xOqwg78BXDAsOu7mRO0VdJ+heZYR4D3oPfIe89\n+B3y7sLvkHfTs+3cObfHzM7D1zt+FXA2foe83wG2ocmxiMic1bSTYxGZfZxz2xi6Xc5rxjj/auDq\nBsdXjmOsp4F3jtDcYMseERGZC5p2cpwNv9osl0SAe8v+YE8okWa1ZHFaj/OR444FvsRatpBcVz7o\nF+e15Pz5OUsiwI88+DAAT+30O88tW7Qgblu5dD4Ane3+27wnRJABKlXfR8eiY+Jj8xd0AnCgxy/I\ny6fvISz06zrgF/V1dibj5At+UX61GiLGmdTv9bBjXyZ8Q9o7kl0Be3rqNw0TERERmdu0IE9ERERE\nJGjayHGu2AJAvpJEh2thP4CeXr/5RYZ8ckHFR1bL4a+pzpJaaXnzublti3zZtXmtSUT3iS6fw3vz\njXcAUMgmfeZqvgrVmWefDMArLnpp3Lb98e0APLVrS3zshNX+s0pLuy+xNjiY5A739vv7qYZ77knl\nI2cyPhKezVbDvScvqxxyqStVf72lPg/lcy2IiIiISEKRYxERERGRQJNjEREREZGgadMqekLps0xq\ncVq17MugdXb4kmkZS1IgBso+JaG/rxz+naQ0LFriF9b1hE3mqoeSEnBl86kJlUHfJ5Z8S4thIV6m\n5BfP9ec747alJ4Udanftio/9bNNmABYuXAjAMc85OW4brIS0iIy/53It+VxTDXkUtbBDXiaXpJK4\nkCaSyfp76enui9sO9SQl6UREREREkWMRERERkVjTRo4Hy34hWmtLsnhu7x6/QG7BQl/OrK3dxW21\nEH21jP+WtJZa47ZciL5GZdR680lktjjfR4Vf9qpfBWBex7y4bcECH02eF56rmfbkBsPCvbYFi+JD\np53h7+v+X/wCgJ0/+0ncduIpzwWg1Bai2P1J9DqT8RuCFEMgvJZayGcZ//knF0WTM8m9V5w+G4mI\niIikaXYkIiIiIhI0beS4o91HfluKyTbLfX0+PzjsLE0uk5Rrq2Wj3Fz/73w++dzQ3upDsrWSjwoP\nVNKRWR+hPvV5zwFg8eIlcVtvj48079sXtojOJn22FMP21v2H4mNLFvqo8ItfdA4AWx98MG7bcu9G\nf87RKwA4+tiVcVu8mUerf32WLuU26CPMDjfsHnLFEiIiIiKSUORYRERERCTQ5FhEREREJGjatAqq\nvu7a4EA5PtTWGtIonC95NtCX7DIXLU6rhbao7BvAgo6lABTCrnvFanJd70C4rjbgrxtnLd3tAAAg\nAElEQVQ8GLcVQkZHa5v/orcvSaFwNd/XokWL42P5nM+H6O3xfZx95ulx2/JjjgHgvvu2AvDME4/E\nbcuO86kWxbDoLpsq5VYZ9PdVDqkg+UJb3NavUm4iIiIiQyhyLCKzgpltMDM39plDrnFmtmGKbklE\nRJpQ00aOKwN+IVqxJZn/l4o+MlsqdQBgJJuA9PT58wfCZhul1qQE3MGufUCyuUaxlCxkK4QFboUW\nHx3OZ5PFerlC2CCk6vvq6joQt7W2+D7Si+dyOf+fo6XFXzc4MBC3HbXYl3xbeO4LAOjuSiLUT+zc\nDUBbu48KF7PJ62pv9QsT+wf9wsGW1uTeB8tJBFxEREREmnhyLCICrAGUPyQiIuPWtJPjwRA5dqlt\nltvbfPQ1E/KLU0FbsmGb6QXz/UYdHanNPHoP+lJpfWHjjf7+5HdtueJzk1sLvs+WXHJdf6+P/Pb1\n+nNqtWTE/tDXgQPJX4krJR9hzud8X4dSm3lUBn2+cmebj3ofs+youK0a1Z8LL7U8kGwQUgpR7qg0\nXSaTRIvntTTtf34RAJxzD0z3PYiIyOyinGMRmXZm9moz+4GZ7TSzATPbYWa3mNl7G5ybM7OPm9lD\n4dwnzewvzazQ4NxhOcdmtj4cX2dm7zCzu82sz8x2m9lXzOzoKXypIiIyw2lyLCLTysx+G7gBOBX4\nL+CzwI1ACbi0wSVfB34PuA34ItAH/CHwpQkO/SHgKuAe4PPA1jDeHWa2ZLQLRUSkeTXt39Vz0U5w\nLilrtmeXX8SWDW2W2iEvWmyXDzvqVcrJYrhcxp+fD+eUa8l1rubTFPIZvwiu3DcYt3X39/nn3lBG\nLdcSt5XCortKare9ffv2A9DW5lMhqqnEj0LO31dfWERX3t8VtxVDzbjuXj9efxgXoFbrBGBeh1+s\nlyEZj9yEFv6LTJV3A4PA85xzu9MNZra4wfknAM91zu0L5/wRfoL7djP7mHPu6XGO+wrgBc65u1Pj\nXQF8EPgM8K7xdGJmG0doWj3O+xARkRlEkWMRmQkqQLn+oHNuT4NzPxpNjMM5PcC1+J9nZ09gzGvS\nE+NgPdAFvMXMisMvERGRZte0keO2Vh+Z7elOoqh7D4TyZ1n/sgfLycK1Gj4avOCgjxgvWDA/bsuF\n0mgunOMyScS1o8Mv4JsfFvIN9Cd9Wvhdn3H+uvaWZAOO1ryP9vakyqn1D/jz+gb9PVsqslsq+TZr\n9eOUk+A1hMh2NXzWKdeS63oH/OLBYouPencW8vWXiUy3a/GpFJvN7DrgFuB259wzI5z/8wbHngzP\nCyYw7i31B5xzXWa2CTgfX+li01idOOfWNjoeIspnTeB+RERkBtD0SESmlXPuc8A7gMeB9wPXA7vM\n7EdmNiwS7Jw7UH8M4nyhbIO2kewa4XiUljFvhHYREWliTRs5LuT9X0QzHam83Taff9tX8ZHVwXKS\nH1wNub+ZECUeHExCs5V8iNqGzblyqRpwg2FzjWiTjWwuiczm877PtpK/rpBNosRtRX9eJrULSLHk\nN+zoPuRLxw1WeuK2KE/6wEFf0q2vJ4lQZ3P+tdacH6eayonO5P2xffu7/WspJpuAVDPpYnYi08c5\n91Xgq2Y2HzgX+HXgncBNZrZ6lCjys3HUCMejahVdI7SLiEgTU+RYRGYM59wB59yNzrnfAq4GFgIv\nmaLhzq8/YGbzgDOAfmDLFI0rIiIzmCbHIjKtzOwCM2v0Z4yl4Xmqdrj7DTM7s+7Yenw6xb855waG\nXyIiIs2uadMq9oeFeIXUjnBR6bLWkk9p6OhojZtcWDRXrYTzLSl55sLv7Uy0E51L0hYOdvtFfn1h\nN7y2UiptoeZTLdrb/OLAUnpHOotSOpIF+sW8b184rxjGTRbLl0p+Md+evb7c28BAqlzbgL/X/gHf\nVyGfjDMQ2vIhheKQS1I1XKZp//PL7HI9cMjM7gS24TevfDHwy8BG4PtTNO73gNvN7JvATuBF4bEN\nuGyKxhQRkRlOsyMRmW6XAS/HV3Z4JT6l4XHgo8AXnXPDSrxNkivwE/MPAm8EDuFTOT5eX2/5MK3c\nsmULa9c2LGYhIiJj2LJlC8DKIz2uOaeNIERk7jCz9cDlwAXOuQ1TOM4AvnrGPVM1hsgYoo1oHpjW\nu5C57Nm+B1cC3c65VZNzO+OjyLGIyNS4D0augywy1aLdG/UelOkyW9+DWpAnIiIiIhJociwiIiIi\nEmhyLCJzinNuvXPOpjLfWEREZi9NjkVEREREAk2ORUREREQClXITEREREQkUORYRERERCTQ5FhER\nEREJNDkWEREREQk0ORYRERERCTQ5FhEREREJNDkWEREREQk0ORYRERERCTQ5FhEREREJNDkWERkH\nM1tuZl8xsx1mNmBm28zs82a2YIL9LAzXbQv97Aj9Lp+qe5fmMBnvQTPbYGZulEfLVL4Gmd3M7PVm\ndqWZ3WZm3eE987XD7GtSfqZOhdx034CIyExnZicAdwBLgRuAB4DnAx8ALjKz85xze8fRz6LQz8nA\nD4HrgNXApcDFZvZC59yjU/MqZDabrPdgyidHOF55Vjcqze4TwPOAQ8BT+J9fEzYF7+dJpcmxiMjY\nvoD/If5+59yV0UEz+xzwIeAvgPeMo59P4SfGn3POfSTVz/uBvw3jXDSJ9y3NY7LegwA459ZP9g3K\nnPAh/KT4YeB84EeH2c+kvp8nmznnpmtsEZEZL0Q4Hga2ASc452qptg5gJ2DAUudczyj9tAO7gRqw\nzDl3MNWWAR4Fjg9jKHosscl6D4bzNwDnO+dsym5Y5gQzW4efHF/rnHvbBK6btPfzVFHOsYjI6C4I\nzzenf4gDhAnu7UArcM4Y/ZwDlIDb0xPj0E8NuKluPJHIZL0HY2b2RjO7zMw+bGavMLPi5N2uyKgm\n/f082TQ5FhEZ3Snh+cER2h8KzycfoX5k7pmK9851wKeBzwI3Ak+Y2esP7/ZEJmTG/yzU5FhEZHTz\nwnPXCO3R8flHqB+ZeybzvXMD8CpgOf4vGavxk+T5wDfMTDnvMtVm/M9CLcgTERGZI5xzV9Qd2gp8\n3Mx2AFfiJ8r/fcRvTGQGUeRYRGR0URRj3gjt0fEDR6gfmXuOxHvnn/Bl3M4Ii6JEpsqM/1moybGI\nyOi2hueR8t9OCs8j5c9Ndj8y90z5e8c51w9EC0XbDrcfkXGY8T8LNTkWERldVMfzwlByLRYibOcB\nvcCdY/RzJ9AHnFcfmQv9Xlg3nkhkst6DIzKzU4AF+AnynsPtR2Qcpvz9/P/bu/Mwua7yzuPft/d9\n077YkryLJRAEBgzDMkAgYRLzJJCEkGQMkwkkQCCQPDGGBBvCEiAMa4YQYshAgsmEMCQsMTNgCLbj\nGGxisBEYL7Is2ZIsqffu6uqqeueP91Td63J1a2upperf53n83O57zj33Vqvc/fbb7znnRCk4FhFZ\nhLvfDXwN2Aq8uq75KiLL9un8epxmdpGZPWznKHefAj6d+l9ZN85r0vjXao1jqbdU70Ez22ZmI/Xj\nm9ka4JPp02vcXbvkyQkzs/b0Pjw3f/543s+nmjYBERE5ggZbne4Enkys13kncEl+q1Mzc4D6jRYa\nbB99M7AduJTYIOSS9IND5GGW4j1oZpcBHwOuJzadOQycDfwcUef5XeB57q66d2nIzF4EvCh9uh54\nPvFe+nY6d9Dd/yD13QrcC9zn7lvrxjmm9/OppuBYROQomNlZwNuI7Z1XEbs4fQG4yt1H6/o2DI5T\n2wjwVuIHzAbgEPBV4E/cfc/JfA1yZjvR96CZPRZ4I7AD2AgMEGUUdwB/D/yluxdP/iuRM5WZXUl8\n/1pILRBeLDhO7Uf9fj7VFByLiIiIiCSqORYRERERSRQci4iIiIgkKy44NrNdZuZm9qzlfhYRERER\nOb2suOBYRERERGQhCo5FRERERBIFxyIiIiIiiYJjEREREZFkRQfHZjZiZu83s3vNbM7M9prZX5nZ\nhkWuebaZ/aOZ7TOzYjp+wcz+8yLXePpvq5ltN7O/MbP7zWzezP5Prt9aM3uvmd1uZtNmVkj9bjSz\nt5nZlgXGX2Nm7zKzH5jZVLr2djN7R6OtQkVERESksRW3CYiZ7QK2AL8B/Gn6eAZoBTpTt13AExrs\nOPSnwJvTpw6ME1tuVncgere7v6nBPatf5N8ktu7sIXYlageudfcXpcD334gdswDKwAQwlBv/d9z9\nY3VjP53YerEaBBeBCtCVPr+f2A70x4t8WURERESElZ05/jAwSuzf3Qv0AZcCY8BW4GFBrpn9Kllg\n/BFgrbsPA2vSWACXm9mvL3LPvwC+AzzW3QeIIPmNqe2tRGB8F/AMoMPdR4Bu4LFEIL+v7pm2AP9M\nBMb/Ezg/9e9N13wNOAv4RzNrPZovioiIiMhKtpIzx/uBR7v7obr2NwLvA+5193PSOQPuBM4DrnH3\nlzYY9++AlxJZ53PdvZJrq36R7wEe4+6zDa7/IbAd+FV3/9xRvpbPAC9j4Yx1BxGM/xTwEnf/h6MZ\nV0RERGSlWsmZ44/XB8ZJtQZ4m5n1po8fTwTGEBncRq5Kx63AxQv0+UijwDiZSMcF653zzKwHeAlR\nQvH+Rn3cvQhUA+LnHc24IiIiIitZ23I/wDL6zgLn9+Y+HgKmgSekzx9y9zsaXeTuPzazvcCm1P+m\nBt3+bZHn+QrwZODPzOx8Iqi9aZFgegfQQdQ+/yCS2w11p+NZi9xbRERERFjZmePJRifdvZD7tD0d\n16TjXha3p65/vYcWufbPgH8iAt7fBb4BTKSVKv7QzIbq+lczzAasW+S/gdSv5wjPLiIiIrLireTg\n+Hh0HbnLosoLNbj7nLtfCjwVeA+Refbc53ea2eNyl1T/7cbd3Y7iv2ed4LOLiIiIND0Fx0enmvE9\nUmnC5rr+x8zdb3L3P3L3pwLDxCS/3UQ2+hO5rvvTccDMBo/3fiIiIiKSUXB8dG5Nx14zazjZzswu\nIOqN8/1PiLtPu/s1wG+nUztykwS/C5SIsooXLMX9RERERFY6BcdH5z+I9YcBrligz5XpuAu4+Vhv\nkJZdW0h1Up4RNcm4+yTw+XT+bWbWv8jYbWbWd6zPJCIiIrLSKDg+Ch6LQb8lfXqpmX3YzFYBmNkq\nM/sQUf4A8Jb8GsfH4HYze6eZPakaKFu4mGyTke/U7dp3OXAYuAC40cxeYGbtuWvPN7M3AD8Cnngc\nzyQiIiKyoqzkTUCe7e7fXKBP9Yuyzd135c7nt4+ukG0fXf0l40jbRz9svLo+Y2ksiIl740A/2YoZ\nB4HnuPv36657ErE288Z0ap5YM7mflGVOnuXu32p0bxEREREJyhwfA3d/C/Ac4ItEsNoHHCKWYHtu\no8D4GFwKvAu4AXggjV0Evg+8m9jN7/v1F7n7d4CLgD8CbgSmiPWZZ4i65A8Bz1RgLCIiInJkKy5z\nLCIiIiKyEGWORUREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEii4FhEREREJFFwLCIiIiKSKDgW\nEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIknbcj+AiEgzMrN7gQFg1zI/iojImWorMOHu207l\nTZs2OP7Ny57mALPFUu3c6v4uAJ70qEcD8MTtP1Vr6+3sBuC+B/cA8ODhA7W2w6OHAJgaHwdg09r1\ntbaR4UEA1q5bB8DMbKXW9v2ddwDQ1dMKwOZ1m2ptq7qHACjNlWvniimR394Rx7n5bKzdDzwEwPnb\nNgPQmfuXOzQ2CkC5FGP19vbW2ubmiwAcHD0czzczU2urVByAV17xcUNEltpAd3f3yPbt20eW+0FE\nRM5EO3fuZHZ29pTft2mD48Nj+wDoTEEvwP7DEdzeuacPgLaW9lrbuqFhACanI3gcn5iotU1Mxsel\n4jwA7R0dtbbOrhi/TASaBw4fqrVVQ1tvidizkAJVgEJbjOVlr50rpivm5+JY9qzqpW9wAICu3p54\nltnpWls5xdfFYnzgnr2RxlJAX7339HSh1tZiqqqR04+Z7QJw963L+yQnbNf27dtHbrnlluV+DhGR\nM9KOHTu49dZbd53q+yo6EhERERFJmjZzLCKy3G7fO87Wy7+83I8hIifBrne/cLkfQU6Spg2O51MZ\nQV9vVlZxaHwOgO/e8UMADh88XGsbaot65Gq97sDwQK2ts7MzzvVEm1eyWuBiMe4zOj4GwP1799Ta\nZotRwtDaHWUcc/PztbZpi9KHztbObKxUH1FJ/Yq5kgtvjeebK0Xb6OHs2dMppqZizLa2rM56bi4+\nnpyKcpHpmazkoqurCxERERHJqKxCRE45C68xszvMrGBme83sI2Y2uMg1LzWz68xsLF2z08zeYmad\nC/S/yMw+ZWb3m1nRzPab2d+Z2YUN+n7KzNzMzjGz15rZ981s1sy+uYQvW0REzgDNmzkuxSS4mals\nAtrYRGSOKy2R+d1zYF+tba4zsrsb2+JL0jKdTXjrTEtD9A32Aw+frFed09a3Kib0eW7dh2qmeDKN\nZeWssdQRbasGV2X9U6a4rTpPMEtQM1+ODPB0Wm1ifHKy1tZukR2fT6tblMvZxL/5+chGF9NkwrlC\n1tba0rT//HL6+wDwe8CDwMeBeeBS4MlAB1DMdzazq4GXA3uAzwNjwFOAtwPPMbPnuXsp1/8FwD8C\n7cA/A3cBm4FfBF5oZs9291sbPNcHgf8EfBn4ClBu0OdhzGyhGXcXHelaERE5/Sg6EpFTyswuIQLj\nu4GL3f1wOv9m4DpgA3Bfrv9lRGD8BeBlnluOxcyuBN4KvJoIbDGzYeCzwAzwDHf/Ya7/Y4CbgE8A\nT2jweE8Aftrd712aVysiImeapg2Oi4WUac1lXwuF+Jk6uCrqiW0ua9y6OjK4vam2t0SW5XWLj8se\n/bu6e2ptnZ3x8dRMqhOez+p9R4aqfyFOWdu5bI3h+ZZIORfnsrrfyam4tq8vzg0MZH9h3n8wstUT\n6bFm57L65fmUvZ5LGWPL5bpmZuOe3am2eaacZcQruXWURU6hl6fjO6qBMYC7F8zsTUSAnPc6oAS8\nIh8YJ28HXgO8jBQcA78JDAGvyQfG6R63m9lfAa83s0fVtwPvOdbA2N13NDqfMsqNAnARETmNNW1w\nLCKnrWrA+K0GbdeTK2Uwsx7gccBBIqBtNN4csD33+VPT8XEps1zvgnTcDtQHxzcv9uAiItL8FByL\nyKlW/ZPI/voGdy+Z2cHcqWHAgDVE+cTRqBby//cj9OtrcG5fg3MiIrKCNG1w3N0Rs9pm5rIJeZ1p\nW+bWSmSfRrr6a20tU1FicDBtG10YyCbAb9y2FQD3mPjW05uVQljaZW9mcgqA2dxEPirxF+Cenhir\nO5f16m+PZynNTdXOFdLW021pwmAlN3mupRz/VOVUTlEqZbUT1bKP+TQBMJ9dq3hM8hufiQl8xfm5\nWltp/mFznkROlfF0XAfck28wszZgNTHxLt/3e+5+tCUK1Wse5+7fP8Zn8yN3ERGRZta0wbGInLZu\nJUornkldcAw8HWitfuLuU2Z2B/BoMxvJ1ygv4ibgl4hVJ441OF5Sj9k0yC3aKEBE5IzSvMFxdaOO\nSpYIakkfFsYjm2zDq2ttkylrO1uM41Qxm/DW0hqT2kozkSWe6Mom1nV3x7nujvhSrh/JlmY7NBV/\nNS6VY8zV7dnGIpsGRwCYKWXZ2z2Hon+vp6xyMZvc19k1FM+SJt9ZJcscF9NGH1Z9rZ7bpKQQmeLD\nhUim9fZmGfGB1obLw4qcbJ8Cfgt4s5l9MbdaRRfwrgb93w/8NXC1mV3m7mP5xrQ6xbbc0myfBN4M\nvNXMvuPuN9f1byFWsfjmEr4mERFpEs0bHIvIacndbzCzDwOvBW43s38gW+d4lFj7ON//ajPbAfwu\ncLeZXQvsBkaAbcAziID4Van/ITN7MbH0201m9nXgDqJk4ixiwt4qQFtEiojIIyg4FpHl8DrgTmJ9\n4lcCh4hg9grgtvrO7v5qM/sqEQA/l1iq7TARJL8X+Exd/6+b2U8BfwA8nyixKAIPAN8gNhIRERF5\nhKYNjjvTNnPtHR3ZyZaYqNYyH+d6O3prTd1dMXF94uBDABRmsnKHsbTG8NxslCiUPSu56OyM+wyn\ntYk3n5WVaqwdWhN90iN05+a/zRw+BMDGbWfVzh2q7npnURbR0Z4ltmoT6VqiHLOno73W1p0m/I2O\njkbfYm4XvEpcd9a6KPc4e8PGWpsVstchciq5uwMfSf/V27rANV8CvnQM99hFrIF8NH0vAy472rFF\nRKR5tSz3A4iIiIiInC6aNnO85azIyBZK2aS2fQ/FMm1r0851XdmkeIoeGdZKS/RvsSyrOjcbE+RL\nlZRpbs0yutNpl739ByMTPDqRLeV2yY7Ya2Dz6shKF8ay5Vu9ENnonmy/Ax69aQMA42ki3th4lgEu\nleI+555zLgC9Pdk/3fx0LAf3QFr8anRstNY2PBD9+npi2bpVPdnufg9NHUBEREREMsoci4iIiIgk\nTZs5vuDc8wCYnc02vZgejQzrlrVRd1scz7K8k+OxOtRsIep+OzqzWuVCKZZ+K8aeHlhbtjzc3Hxk\nfrva40s5ti/Lxu66I373GHrMhQAMDK+rtXWsXhtjW64mOpURd1hcd96FWf+W1uj3wP4HAKiUsusu\nOu8cAFanuuI7bsuWdp0dj9fcZfGcEwez5/PccnAiIiIiosyxiIiIiEiNgmMRERERkaRpyyr+9V+v\nA2DD6k21c+dvjvKDLevj3M6HflBrO3hwHwCFudj9buuGc7O20ThXLsSkuMncxLqutEPeeeu3ATB7\nKNs9r5Amxs2X4neQzt41tbaewZgYN1/JJt3NzE6lc7HkXGtbf64tJvDdeP0NALS3Zf90Q0Ox296W\nczcDcJFnJRe7frIbgH37Y7ZeIds8jznPJiSKiIiIiDLHIiIiIiI1TZs5np2LSXS79+6unZuejgl4\nU4diUtrU6OFaW3daGm3z2WcD8Kjt59Xa9u6JTPGePZG9zbbfgE2bY/m1wbQJSHc5y/YODcQSbt29\ncRxNy70B3Hf3TwCYr87yAwqFeL5iJTK6k1sms7GGY9zh/jjOzWUTDfft3QvAug0xga91MJvIt/Yx\n6wH43n2RGW9t6661lQwRERERyVHmWEREREQkadrMcXd7bKnc09lZO2eVyCa3pXrdJz7p0bW2isey\nZr29kQEeGco2y+jpSJnYcvwusWpuuNY2sjrqfWfGI7vc25PV+3b1xhjjaZOOUm5b54MPRra3MDVR\nOzc/F1nk1s64rr872956birql1cPROa4oyurX7ZyFBI/uDvGrAyvr7UNb4hM+KqBGHNfdacQYDo9\nl4iIiIgEZY5FRERERBIFxyIiIiIiSdOWVfR4xP3r+vpq5zrbY6Lb4ECUKwwMZZPTulM5RDFNkLO2\nbMJbz2CMtfHs1dGnnJVqlMtRjlGail3z+nuzMbt6okSjmHaiG50cr7UVUxlHmWy3vfk0ya66cd2u\nu+7MvaIondi6NZahO+ecbdl90mt88N57AFibKyUZ7I/l66oTBvfPF2ptfW25dd1ETpCZbQXuBf7G\n3S9b1ocRERE5Tsoci4iIiIgkTZs5Xt0Xk+baPVuvrFyIrOlD0zEJri83eW5gW2yg0ZKyrvPlUq2t\nrSP6jWwYAmD0cNZ26EB1Q5DIwnZ0ZBtrDA4ORP+56D8+nW0QQinSw5UscYy1x30Kxehfnsn6r1sz\nGM9CvJ7JyelaW3t3TNI7a31MHOwgu85K8VoPTkRGfLaU3bC3I3v9IiIiItLEwbGIyHK7fe84Wy//\n8nI/xmlv17tfuNyPICJSo7IKEVlyZrbVzK4xs4NmVjCz75rZf2nQr9PMLjezH5jZjJlNmNm3zeyX\nFxjTzexTZnaBmX3OzA6YWcXMnpX6nGNmHzezu8xs1swOp7E/ZmarGoz5UjO7zszG0nPuNLO3mFln\nfV8REVkZmjZz3J7WMm5pzeJ/a4uP+y1N0pvNJqTtuus+AAppMlxLezaxbnBVlDKcvW1jXDaTrQ88\ndSg+7u+OEoXe3myHPE81Ew/tjx35ijPZOseW2lpbstIG64z7jI/GTnojXVlJyLrBmFBXLff4wQ9/\nXGtbOxrPsGkkXtfAZDbprnUk1kO+e2fsyNdSytZV7urNSkBEltAW4GbgHuDTwAjwK8AXzey57n4d\ngJl1ANcCzwR+BHwU6AFeDHzOzB7v7lc0GP9c4N+BO4G/BbqBCTPbAHwHGAC+Anwe6AK2Ab8BfASo\nbVNpZlcDLwf2pL5jwFOAtwPPMbPnuXtWQyUiIitC0wbHIrJsngVc6e5XVU+Y2d8B/wL8IXBdOv1G\nIjD+KvAL1UDUzK4igus3mdmX3P3GuvGfDryrPnA2s9cSgfjr3f2DdW29VCcGxOeXEYHxF4CXufts\nru1K4K3Aq4GHjdOImd2yQNNFR7pWREROP00bHG9ZHxnc6elsSbZKJV7u/FxkbSems0xuV8oUj8/E\nz8j53G52xVIkj4ZXxW545fn5rK0Qk9+qP1ndswlvs2lC3eho7G7X3TtYaysX4+d0YS67z+T4YQBm\nJqP/pr6RWltHd/yVd/dEtN1x795aW3/aGe+CjfFX46c9+cJa2+7U7867dwNw0QWbam3Wrb8cy0lx\nH/Cn+RPufq2Z7QYuzp1+BeDAG/IZWnc/YGZvBz4B/BZQHxzvB65iYbP1J9x9uu7U64AS8Ip8YJy8\nHXgN8DKOIjgWEZHm0rTBsYgsm/9wTwt5P9z9wFMBzKwfOA/Y6+4/atD3G+n40w3abnP3uQbn/wl4\nJ/BRM3s+UbJxA/BDz/3WamY9wOOAg8DrzazBUMwB2xs11HP3HY3Op4zyE45mDBEROX00bXDc3RUv\nLf8jupgyxvNt8cOw2JLV3BZSsfH4XGR0h/qGam3TKQP83VtuA2Dd0Ppa2+BQZKgPHYgM7fh4ttGH\nt0Y98Uy6vq2zJ3uY9PN4YjqrX56ejX4jQ1E7vOHsLMs7RTzrjMWxezB7vj337j5LZcYAABHeSURB\nVAFgoBLJsd5nZD+rv37zDwDYfyhqjTcWNtbaKu0NgwKREzW2wPkS2STg6p9RHlygb/X8UIO2fY0u\ncPf7zOxi4ErgBcAvpqb7zex97v6h9Pkw8X/gGqJ8QkREpEarVYjIcqj+Frl+gfYNdf3yvMG5aHDf\n6e6/AqwCnghcTnyf+6CZ/be6Mb/n7rbYf8f0ikREpCkoOBaRU87dJ4G7gU1mdn6DLs9Ox1uPc/yS\nu9/i7n8GvDSdflFqmwLuAB5tZiMLjSEiIitT05ZVTFvsTte1OitlaE/Lp3WW2wHw3DJv5fYoq7DZ\nKGWsFLOkUUtHbxxTn+lKdl1Xf9yneyomyo2NZX9RnpyJsYpph7xCbpJfpRyT+qZzu+BVUkKsf/3q\neJbVa2ptY4Xo37M62tZ1ZfOLRvfF6lRt6fqp8axU44YbvwdAR1sqx+jKTcJradp/fjkzXA28A3iv\nmf1StU7ZzFYDf5zrc1TMbAdwl7vXZ5vXpWNui0reD/w1cLWZXebuDysFMbNhYJu7H1dwXvWYTYPc\nog0uRETOKIqORGS5vA/4WeBS4DYz+wqxzvFLgLXAe9z9+mMY7zeAV5rZ9URWepRYE/nniQl2H6h2\ndPerUzD9u8DdZnYtsJtYCm4b8Azgk8CrTugViojIGadpg+PO1ecCkJtzR1trTLaztPlHuZJb3781\nssJDPTFPqDiXZY7LaSm3YlohqlzKSh6r2ef+gZg31EW2zNvB0UhgtbTHBh6tnVnWtjAVWWRvyx5w\ncDgyxd3rogxzX+7xxgtxz5ZCWqq1lF23Zu1aAM4/O/5CXMhNQjx4MJaH6+6If+rurvZa29Ca1Ygs\nF3cvmtnzgDcAvwa8lpi0dxuxVvFnj3HIzwKdwCXADmJzkL3ANcCfu/vtdfd/tZl9lQiAn0tM/jtM\nBMnvBT5znC9NRETOYE0bHIvIqeXuu6itw9Kw/VkNzhWI5dfeuQTj/zuxc95Rc/cvAV86lmtERKS5\nNW1w3NkRWdqp6cnaOU8bZLW2RfZ0bDorQWxNCdXunsgEd3dlmdlyytLOjkUNcVtHtuXzgbTVc3uq\nCd7Sl9U4b9kSpY53T8bP81JnX61tZDhlbXsGaueqNck774+Mc4XRWltXyvwOdA8DMF/K0sq9w5Ht\n7h6JZeVmcrXEpVI8c8dw1E33j6yqtVVaNB9TREREJE/RkYiIiIhIouBYRERERCRp2rKK0UP7Abj/\n/j21cz09UfLQMxDlBxXLJtbNz0dZxHwhJt319ffX2vr7o2yhqyMmvs3NZTvXFrpi2bTulugzO5uV\namzYEv13z8fudPO5bWqrJQ1Da9bWzvX2RulDIY3f1ZX97jLYF5P65qejnGJ8qpBd156WmuuI/vfv\nzTYds1RKMjg0mJ49mzD44J7sayMiIiIiyhyLiIiIiNQ0bea4xSNjunljtjttpRzn+tLGHYX5bFOO\nvr5YBm1mJm2gUc6yyoXpyCYXU//O3JJsj77oIgBa52P9tId+fE825nBMflszHb+DlNqyCXmtaQm3\n9vZsabXpNEGwqyMyzGtXZ9nrtSPxzC2V6D85lWWAC5MxcW+mEMfR0WwTkP7uyCqPDMZSc14qP6JN\nRERERIIyxyIiIiIiiYJjEREREZGkacsqhtOku1WrsnV99++PSXpj4zFBrjifrRU81BuT9UZSycXe\nB7NJbe1daVc6otRiajY3GS7tOFdOJRejhaxtfSq16GiJMomKZyUNrWnrvt6ertq5UjGuHZ+IdY6H\nztlca+vvjZIMK8XvM3Mz2VjzaazpuXjOiensGQZ6ugF41IUXxufDQ7W2A4cOIiIiIiIZZY5FRERE\nRJKmzRyPpF3jxseyXeZKKbtrlciwrhrIsqikLK+neXjDA4O1pt70saUMcHtbNomupS0uGB6JiX9j\nD47X2n5yzy4ANmzaAkDPqo21ttlithxcVfuq2P1ubVrerTu3o97keEzWK0zGa5iZySYTtqfJfS3t\nkSWeLWST9YZSJrwvTb4r5HYFLMzMPuIZRERERFYyZY5FRERERJKmzRxPTkWGtK0jW3Zt46bIFM+m\nmuGuru5am6el31pb4/eFQq52uLc7+rWn2t6+zuy6zs7IIs9VIls71Je1TbdG5nfNutXxeTmrE67W\nH/f0ZMu1ldPycZaOe3c/UGsrzUemuaOt82GvAaCtNfqvGonX19qb1TFXJiM7fN/9u+O6QpYtLlcq\niIiIiEhGmWMRERERkUTBsYicUcxsl5ntWu7nEBGR5tS0ZRX9QzG5raOjo3auK+1sNzQSvxMcPJhb\nysxist1MmqRmlu2QNzkdO861En2snJUjjI7GxLh9E4cBmChku9P19sYkuNnZKPHYPzqZPUtvTPIr\n5MojRkdjibmOVNrRmp4JoFiMZeemquUirdk/3Xxakq61M15zOffss2kS4nxpPvXNJutVVFYhIiIi\n8jBNGxyLiCy32/eOs/XyLy/aZ9e7X3iKnkZERI5G0wbHxZQpbe/MMsfV5dMmJiKDe999u2tthw4d\nAqCnJzYD6cpvzlGOzOx8MbKwfd09tbZqlrbcHRPzOvIT8mYjC726nJaAa8m+3A/tiw1JKuUsO1xI\nS7B1dsRYI7kNO0qleIZymtTnlSw7bMS5ubl4fTMz2XJts+nj6hJ17e3ZMnTl3ARBEREREVHNsYic\nhiy8xszuMLOCme01s4+Y2eAC/TvN7HIz+4GZzZjZhJl928x+eZHxX2dmP6wfXzXNIiIrW9Nmjg+P\njwHQ3ddbO1fNqO4/GFniAwfHam3u8XtCT39ka+fmsiXPBgfj57GnGuAKWda2JW0McnA8NhtZNzBQ\na5uajDrk0fa4z8azzq61lSsH4roDh2vnSnORmS6numDL3aeWMa6mgLMmCrNR51wqx+sbG802Plm7\nNjYUGU5Z6MnJrO7ZcjXNIqeZDwC/BzwIfByYBy4Fngx0ALVdcMysA7gWeCbwI+CjQA/wYuBzZvZ4\nd7+ibvyPAr8DPJDGLwK/AFwMtKf7iYjICtS0wbGInJnM7BIiML4buNjdD6fzbwauAzYA9+UueSMR\nGH8V+AV3L6X+VwE3A28ysy+5+43p/H8iAuM7gSe7+1g6fwXw/4CNdeMf6XlvWaDpoqMdQ0RETh8q\nqxCR083L0/Ed1cAYwN0LwJsa9H8F8beUN1QD49T/APD29Olv5fr/19z4Y7n+xQXGFxGRFaRpM8f3\n7bkfgD0PZrvMjY+PA+CVeNntHdmku77e2M1uLi2LRiUrOagUY8mziZlpAIqV3E53adm12fEobTg4\nmS3NVk4lDA/Mxl+Ax2eytorFbntd7dmEwTaLyXLFUvSfnc1KO6oT6aoT80rzpey6tng9e/fujety\nu/uNDMdrrFZj5EspWlr0u5Gclp6Qjt9q0HY9UPsf0Mz6gfOAve7+owb9v5GOP507V/34+gb9bwJK\nDc4vyN13NDqfMspPaNQmIiKnL0VHInK6qU6621/fkDLDBxv0fXCBsarnh3LnFhu/DBw66icVEZGm\n07SZ42rU397aWju3emQEgLa2znTMljWrZlZ701JultsgozNlbbt7Iws7PpVt9FHdXGMgbTpyYF/2\nM7qzNa5rTRuRPLBvX62tP03y62jPstdV7R3x9C2e/fOU0n1KKatcyi3D1tffD8CQrQKgp7e/1taS\nstGHRiMO6O7KlpqbnJ5+xL1FTgPj6bgOuCffYGZtwGpgT13f9QuMtaGuH8DEIuO3AquAvcf81CIi\n0hSaNjgWkTPWrUQ5wjOpC16BpwO133jdfdLM7gbOMbPz3f0ndf2fnRuz6ntEacXTG4z/FJbw++Jj\nNg1yizb5EBE5o6isQkRON59Kxzeb2Uj1pJl1Ae9q0P9qwID3psxvtf9q4I9zfar+V278wVz/DuCd\nJ/z0IiJyRmvazPHWs84FoDU36WwiTZDr6oxShpbWrM2oTlTLLSCczKdJcO1p8lx/T1a2UC5FeUN1\nbeLevmyPghaL8T2VZazZkJU99vbHBMDqBDvI1jCu7sTX1ZKVhHSk0ozqhLr8xLpKKgHp6x9Obdnr\nmp2N0on5+UK6b7YOc0vrI0s6RJabu99gZh8GXgvcbmb/QLbO8SiPrC9+H/Czqf02M/sKsc7xS4C1\nwHvc/frc+N8ys48Dvw3cYWafT+P/PFF+8QBQQUREVqSmDY5F5Iz2OmId4lcDryQmyX0BuAK4Ld/R\n3Ytm9jzgDcCvEUF1KfV7vbt/tsH4v0NsGPJK4FV14+8h1lg+UVt37tzJjh0NF7MQEZEj2LlzJ8DW\nU31fq+24JiKywpnZ+URQfo27v/QEx5oj6qNvO1JfkWVS3aim0TKIIqeDxwFld+88lTdV5lhEVhwz\nWw8ccPdK7lwPsW01RBb5RN0OC6+DLLLcqrs76j0qp6tFdiA9qRQci8hK9HrgpWb2TaKGeT3wHGAz\nsQ31/16+RxMRkeWk4FhEVqL/S/y57meAEaJG+U7gQ8AHXPVmIiIrloJjEVlx3P3rwNeX+zlEROT0\no3WORUREREQSBcciIiIiIomWchMRERERSZQ5FhERERFJFByLiIiIiCQKjkVEREREEgXHIiIiIiKJ\ngmMRERERkUTBsYiIiIhIouBYRERERCRRcCwichTMbLOZXW1mD5jZnJntMrMPmNnwMY4zkq7blcZ5\nII27+WQ9u6wMS/EeNbNvmpkv8l/XyXwN0rzM7MVm9mEz+7aZTaT302eOc6wl+X68kLalGEREpJmZ\n2bnAjcBa4IvAj4CLgdcBLzCzp7n7oaMYZ1Ua5wLgG8A1wEXAy4EXmtlT3f2ek/MqpJkt1Xs056oF\nzpdO6EFlJXsL8DhgCthDfO87Zifhvf4ICo5FRI7sL4hvxL/n7h+unjSz9wO/D7wDeNVRjPNOIjB+\nv7u/MTfO7wEfTPd5wRI+t6wcS/UeBcDdr1zqB5QV7/eJoPgu4JnAdcc5zpK+1xvR9tEiIotIWYq7\ngF3Aue5eybX1Aw8CBqx19+lFxukDDgAVYIO7T+baWoB7gC3pHsoey1Fbqvdo6v9N4JnubiftgWXF\nM7NnEcHx37r7rx/DdUv2Xl+Mao5FRBb37HT8Wv4bMUAKcG8AeoCnHGGcpwDdwA35wDiNUwGurbuf\nyNFaqvdojZn9ipldbmZvMLOfNbPOpXtckeO25O/1RhQci4gs7sJ0vHOB9p+k4wWnaByReifjvXUN\n8C7gz4GvALvN7MXH93giS+aUfB9VcCwisrjBdBxfoL16fugUjSNSbynfW18Efh7YTPyl4yIiSB4C\nPmdmqomX5XRKvo9qQp6IiIgA4O7/o+7Uj4ErzOwB4MNEoPwvp/zBRE4hZY5FRBZXzUQMLtBePT92\nisYRqXcq3lufIJZxe3ya+CSyHE7J91EFxyIii/txOi5Uw3Z+Oi5UA7fU44jUO+nvLXcvANWJpL3H\nO47ICTol30cVHIuILK66FufPpCXXalIG7WnADHDTEca5CZgFnlafeUvj/kzd/USO1lK9RxdkZhcC\nw0SAfPB4xxE5QSf9vQ4KjkVEFuXudwNfA7YCr65rvorIon06v6ammV1kZg/b/cndp4BPp/5X1o3z\nmjT+tVrjWI7VUr1HzWybmY3Uj29ma4BPpk+vcXftkicnlZm1p/foufnzx/NeP677axMQEZHFNdiu\ndCfwZGLNzTuBS/LblZqZA9RvpNBg++ibge3ApcQGIZekb/4ix2Qp3qNmdhnwMeB6YlOaw8DZwM8R\ntZzfBZ7n7qqLl2NmZi8CXpQ+XQ88n3iffTudO+juf5D6bgXuBe5z96114xzTe/24nlXBsYjIkZnZ\nWcDbiO2dVxE7MX0BuMrdR+v6NgyOU9sI8Fbih8QG4BDwVeBP3H3PyXwN0txO9D1qZo8F3gjsADYC\nA0QZxR3A3wN/6e7Fk/9KpBmZ2ZXE976F1ALhxYLj1H7U7/XjelYFxyIiIiIiQTXHIiIiIiKJgmMR\nERERkUTBsYiIiIhIouBYRERERCRRcCwiIiIikig4FhERERFJFByLiIiIiCQKjkVEREREEgXHIiIi\nIiKJgmMRERERkUTBsYiIiIhIouBYRERERCRRcCwiIiIikig4FhERERFJFByLiIiIiCQKjkVERERE\nEgXHIiIiIiLJ/wdOSnC+voAxAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fe9c2f320>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
